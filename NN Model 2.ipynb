{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "121a30ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tensorboard extension is already loaded. To reload it, use:\n",
      "  %reload_ext tensorboard\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "import pickle\n",
    "import time, datetime, os\n",
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "06759a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"264x32x16x1_MSE_sigmoid_glo_6ep{}\".format(int(time.time()))\n",
    "\n",
    "log_dir = \"logs/fit/\" + NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "stats = pd.read_csv(r'Data\\final_dataset.csv')\n",
    "stats = stats.drop('Score',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391017cc",
   "metadata": {},
   "source": [
    "**Custom Loss Function**\n",
    "Keras does not allow to give any parameter other than y_true and y_pred, to get around we encode the odds in the y_true tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "77f61eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stats.iloc[:,3:-3]\n",
    "y = stats.iloc[:,-1:]\n",
    "#y = stats.iloc[:,-3:]\n",
    "#y = tf.convert_to_tensor(y)\n",
    "def custom_loss(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    y_true = (batch_size, output nodes)\n",
    "    y_pred = (batch_size, output nodes)\n",
    "    \"\"\"\n",
    "    odds1 = y_true[:, 0:1]\n",
    "    odds2 = y_true[:, 1:2]\n",
    "    y_true = y_true[:, :-1]\n",
    "    loss = -1 * K.sum((odds1 * y_true -1) * K.log(odds1 * y_pred -1) + (odds2 * (1- y_true) -1) * K.log(odds2 * (1-y_pred)-1))\n",
    "    \n",
    "    return loss\n",
    "    \n",
    "\n",
    "random_state = 12\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state=random_state)\n",
    "X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "9161915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/6\n",
      "   2/2288 [..............................] - ETA: 6:50 - loss: 0.2507 - accuracy: 0.4000WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0199s vs `on_train_batch_end` time: 0.3392s). Check your callbacks.\n",
      "2288/2288 [==============================] - 2s 944us/step - loss: 0.2220 - accuracy: 0.6450 - val_loss: 0.2135 - val_accuracy: 0.6563\n",
      "Epoch 2/6\n",
      "2288/2288 [==============================] - 2s 740us/step - loss: 0.2171 - accuracy: 0.6555 - val_loss: 0.2132 - val_accuracy: 0.6657\n",
      "Epoch 3/6\n",
      "2288/2288 [==============================] - 2s 746us/step - loss: 0.2149 - accuracy: 0.6619 - val_loss: 0.2117 - val_accuracy: 0.6748\n",
      "Epoch 4/6\n",
      "2288/2288 [==============================] - 2s 737us/step - loss: 0.2131 - accuracy: 0.6659 - val_loss: 0.2110 - val_accuracy: 0.6689\n",
      "Epoch 5/6\n",
      "2288/2288 [==============================] - 2s 777us/step - loss: 0.2114 - accuracy: 0.6706 - val_loss: 0.2116 - val_accuracy: 0.6741\n",
      "Epoch 6/6\n",
      "2288/2288 [==============================] - 2s 748us/step - loss: 0.2091 - accuracy: 0.6701 - val_loss: 0.2114 - val_accuracy: 0.6759\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22c870c7670>"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Sequential()\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "model.add(Dense(264, input_dim=264, kernel_initializer='normal', activation='relu', bias_regularizer=l2(0.01)))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu', bias_regularizer=l2(0.01)))\n",
    "model.add(Dense(16, kernel_initializer='normal', activation='relu', bias_regularizer=l2(0.01)))\n",
    "model.add(Dense(1, kernel_initializer='GlorotNormal', activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='MeanSquaredError', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size= 5, epochs=6, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "ae6eafc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "90/90 [==============================] - 0s 740us/step - loss: 0.2114 - accuracy: 0.6759\n",
      "0.2114359438419342 0.6758741140365601\n"
     ]
    }
   ],
   "source": [
    "val_loss, val_acc = model.evaluate(X_test, y_test)\n",
    "print(val_loss, val_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "f1875eec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generate a prediction\n",
      "WARNING:tensorflow:11 out of the last 11 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000022C87564040> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/tutorials/customization/performance#python_or_tensor_args and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "prediction: [[0.19128305]\n",
      " [0.43825045]\n",
      " [0.2619453 ]\n",
      " [0.22829315]\n",
      " [0.452913  ]\n",
      " [0.55657303]\n",
      " [0.74520147]\n",
      " [0.48667052]\n",
      " [0.45464498]\n",
      " [0.6408756 ]\n",
      " [0.6918521 ]\n",
      " [0.79550266]\n",
      " [0.61743057]\n",
      " [0.58354485]\n",
      " [0.2593447 ]\n",
      " [0.29844815]\n",
      " [0.25415578]\n",
      " [0.3739645 ]\n",
      " [0.64564496]\n",
      " [0.5540498 ]]\n",
      "       Results\n",
      "12047      1.0\n",
      "5092       0.0\n",
      "4915       1.0\n",
      "7563       0.0\n",
      "6054       0.0\n",
      "5913       1.0\n",
      "10748      1.0\n",
      "4061       1.0\n",
      "8971       1.0\n",
      "6588       1.0\n",
      "6381       0.0\n",
      "13380      1.0\n",
      "2109       1.0\n",
      "7189       1.0\n",
      "5750       0.0\n",
      "636        1.0\n",
      "7703       0.0\n",
      "3242       0.0\n",
      "3803       0.0\n",
      "8766       0.0\n"
     ]
    }
   ],
   "source": [
    "print(\"Generate a prediction\")\n",
    "prediction = model.predict(X_test[:20])\n",
    "print(\"prediction:\", prediction)\n",
    "print(y_test[:20]) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "969441d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Reusing TensorBoard on port 6006 (pid 18168), started 2:03:48 ago. (Use '!kill 18168' to kill it.)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "      <iframe id=\"tensorboard-frame-8dd43b95e8c685ec\" width=\"100%\" height=\"800\" frameborder=\"0\">\n",
       "      </iframe>\n",
       "      <script>\n",
       "        (function() {\n",
       "          const frame = document.getElementById(\"tensorboard-frame-8dd43b95e8c685ec\");\n",
       "          const url = new URL(\"/\", window.location);\n",
       "          const port = 6006;\n",
       "          if (port) {\n",
       "            url.port = port;\n",
       "          }\n",
       "          frame.src = url;\n",
       "        })();\n",
       "      </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d59f82ce",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b2857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e3be23f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5f3cd50d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "_sc = StandardScaler()\n",
    "_pca = PCA(n_components = None)\n",
    "_model = LogisticRegression()\n",
    "log_regress_model = Pipeline([\n",
    "    ('std_scaler', _sc),\n",
    "    ('pca', _pca),\n",
    "('regressor', _model)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9edee1bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bei\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:63: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(*args, **kwargs)\n",
      "C:\\Users\\Bei\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('std_scaler', StandardScaler()), ('pca', PCA()),\n",
       "                ('regressor', LogisticRegression())])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# perform a split\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "    train_test_split(X, y, \n",
    "                     test_size=0.3,\n",
    "                     shuffle=True, \n",
    "                     random_state=random_state)\n",
    "# train the model using the PCA components\n",
    "log_regress_model.fit(X_train,y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "48397b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6631701631701632"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_regress_model.score(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080accb0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
