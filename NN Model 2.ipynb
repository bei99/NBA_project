{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f54684",
   "metadata": {},
   "source": [
    "#### Import the relevant librries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "121a30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import time, datetime, os\n",
    "#%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfba15b",
   "metadata": {},
   "source": [
    "####  Set tensorboard and import final_dataset as stats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "06759a0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>HOME</th>\n",
       "      <th>AWAY</th>\n",
       "      <th>AST _ewm10</th>\n",
       "      <th>BLK _ewm10</th>\n",
       "      <th>DREB _ewm10</th>\n",
       "      <th>FG_PCT _ewm10</th>\n",
       "      <th>FG3_PCT _ewm10</th>\n",
       "      <th>FG3A _ewm10</th>\n",
       "      <th>FG3M _ewm10</th>\n",
       "      <th>...</th>\n",
       "      <th>OPP_PTS_OFF_TOV_ewm5ha</th>\n",
       "      <th>OPP_PTS_PAINT_ewm5ha</th>\n",
       "      <th>PTS_2ND_CHANCE_ewm5ha</th>\n",
       "      <th>PTS_FB_ewm5ha</th>\n",
       "      <th>PTS_OFF_TOV_ewm5ha</th>\n",
       "      <th>PTS_PAINT_ewm5ha</th>\n",
       "      <th>Score</th>\n",
       "      <th>Odds1</th>\n",
       "      <th>Odds2</th>\n",
       "      <th>Results</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>28/10/2008</td>\n",
       "      <td>BOS</td>\n",
       "      <td>CLE</td>\n",
       "      <td>-0.053016</td>\n",
       "      <td>0.008363</td>\n",
       "      <td>0.014856</td>\n",
       "      <td>-0.000706</td>\n",
       "      <td>0.000401</td>\n",
       "      <td>0.096037</td>\n",
       "      <td>0.040449</td>\n",
       "      <td>...</td>\n",
       "      <td>0.433684</td>\n",
       "      <td>-0.361584</td>\n",
       "      <td>0.104689</td>\n",
       "      <td>-0.785678</td>\n",
       "      <td>-0.016826</td>\n",
       "      <td>-0.015002</td>\n",
       "      <td>90:85</td>\n",
       "      <td>1.36</td>\n",
       "      <td>3.15</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>28/10/2008</td>\n",
       "      <td>CHI</td>\n",
       "      <td>MIL</td>\n",
       "      <td>-0.001185</td>\n",
       "      <td>-0.004342</td>\n",
       "      <td>-0.058237</td>\n",
       "      <td>-0.000422</td>\n",
       "      <td>-0.001997</td>\n",
       "      <td>-0.150581</td>\n",
       "      <td>-0.082637</td>\n",
       "      <td>...</td>\n",
       "      <td>0.120543</td>\n",
       "      <td>-0.110391</td>\n",
       "      <td>0.363791</td>\n",
       "      <td>0.588124</td>\n",
       "      <td>-0.552351</td>\n",
       "      <td>1.246822</td>\n",
       "      <td>108:95</td>\n",
       "      <td>1.36</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>28/10/2008</td>\n",
       "      <td>LAL</td>\n",
       "      <td>POR</td>\n",
       "      <td>-0.081911</td>\n",
       "      <td>0.001941</td>\n",
       "      <td>0.027199</td>\n",
       "      <td>-0.001031</td>\n",
       "      <td>-0.001619</td>\n",
       "      <td>0.030843</td>\n",
       "      <td>-0.018690</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.056882</td>\n",
       "      <td>0.159378</td>\n",
       "      <td>-0.498689</td>\n",
       "      <td>-3.364871</td>\n",
       "      <td>-0.313756</td>\n",
       "      <td>-0.855125</td>\n",
       "      <td>96:76</td>\n",
       "      <td>1.27</td>\n",
       "      <td>3.85</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>29/10/2008</td>\n",
       "      <td>DET</td>\n",
       "      <td>IND</td>\n",
       "      <td>0.052314</td>\n",
       "      <td>0.020826</td>\n",
       "      <td>-0.020202</td>\n",
       "      <td>0.000044</td>\n",
       "      <td>0.000531</td>\n",
       "      <td>0.045038</td>\n",
       "      <td>0.029248</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.008929</td>\n",
       "      <td>1.189835</td>\n",
       "      <td>0.620750</td>\n",
       "      <td>2.002133</td>\n",
       "      <td>1.740860</td>\n",
       "      <td>0.471794</td>\n",
       "      <td>100:94</td>\n",
       "      <td>1.13</td>\n",
       "      <td>5.75</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29/10/2008</td>\n",
       "      <td>GSW</td>\n",
       "      <td>NOP</td>\n",
       "      <td>-0.026685</td>\n",
       "      <td>0.038596</td>\n",
       "      <td>0.004095</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>-0.000702</td>\n",
       "      <td>-0.142057</td>\n",
       "      <td>-0.061073</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.777967</td>\n",
       "      <td>0.603658</td>\n",
       "      <td>-0.257766</td>\n",
       "      <td>0.099136</td>\n",
       "      <td>-0.461950</td>\n",
       "      <td>-0.713632</td>\n",
       "      <td>103:108</td>\n",
       "      <td>3.35</td>\n",
       "      <td>1.32</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14295</th>\n",
       "      <td>10/04/2022</td>\n",
       "      <td>NYK</td>\n",
       "      <td>TOR</td>\n",
       "      <td>0.035821</td>\n",
       "      <td>0.015852</td>\n",
       "      <td>0.037074</td>\n",
       "      <td>-0.000346</td>\n",
       "      <td>0.000882</td>\n",
       "      <td>0.100520</td>\n",
       "      <td>0.063328</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.236713</td>\n",
       "      <td>-0.154263</td>\n",
       "      <td>-0.810998</td>\n",
       "      <td>-1.268378</td>\n",
       "      <td>-0.856542</td>\n",
       "      <td>-0.941926</td>\n",
       "      <td>105:94</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14296</th>\n",
       "      <td>10/04/2022</td>\n",
       "      <td>ORL</td>\n",
       "      <td>MIA</td>\n",
       "      <td>-0.004794</td>\n",
       "      <td>0.036993</td>\n",
       "      <td>0.051106</td>\n",
       "      <td>-0.001918</td>\n",
       "      <td>-0.002143</td>\n",
       "      <td>0.085899</td>\n",
       "      <td>-0.050124</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.372876</td>\n",
       "      <td>0.077874</td>\n",
       "      <td>0.597325</td>\n",
       "      <td>-0.290637</td>\n",
       "      <td>-0.696616</td>\n",
       "      <td>0.265701</td>\n",
       "      <td>125:111</td>\n",
       "      <td>3.41</td>\n",
       "      <td>1.34</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14297</th>\n",
       "      <td>10/04/2022</td>\n",
       "      <td>PHI</td>\n",
       "      <td>DET</td>\n",
       "      <td>0.045087</td>\n",
       "      <td>-0.011308</td>\n",
       "      <td>0.016990</td>\n",
       "      <td>0.001253</td>\n",
       "      <td>0.001721</td>\n",
       "      <td>-0.060110</td>\n",
       "      <td>0.050316</td>\n",
       "      <td>...</td>\n",
       "      <td>0.554088</td>\n",
       "      <td>-0.275713</td>\n",
       "      <td>0.322300</td>\n",
       "      <td>-0.649111</td>\n",
       "      <td>-0.162648</td>\n",
       "      <td>1.015744</td>\n",
       "      <td>118:106</td>\n",
       "      <td>1.37</td>\n",
       "      <td>3.24</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14298</th>\n",
       "      <td>10/04/2022</td>\n",
       "      <td>PHX</td>\n",
       "      <td>SAC</td>\n",
       "      <td>0.080521</td>\n",
       "      <td>-0.009226</td>\n",
       "      <td>0.047192</td>\n",
       "      <td>0.000443</td>\n",
       "      <td>0.000586</td>\n",
       "      <td>0.027357</td>\n",
       "      <td>0.024687</td>\n",
       "      <td>...</td>\n",
       "      <td>0.285610</td>\n",
       "      <td>-0.141892</td>\n",
       "      <td>0.227124</td>\n",
       "      <td>1.075718</td>\n",
       "      <td>0.597625</td>\n",
       "      <td>0.317031</td>\n",
       "      <td>109:116</td>\n",
       "      <td>1.19</td>\n",
       "      <td>5.16</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14299</th>\n",
       "      <td>10/04/2022</td>\n",
       "      <td>POR</td>\n",
       "      <td>UTA</td>\n",
       "      <td>0.036937</td>\n",
       "      <td>-0.025378</td>\n",
       "      <td>-0.131900</td>\n",
       "      <td>-0.000616</td>\n",
       "      <td>-0.000499</td>\n",
       "      <td>-0.090065</td>\n",
       "      <td>-0.044900</td>\n",
       "      <td>...</td>\n",
       "      <td>1.102207</td>\n",
       "      <td>1.208529</td>\n",
       "      <td>1.235325</td>\n",
       "      <td>1.026042</td>\n",
       "      <td>0.564374</td>\n",
       "      <td>0.419334</td>\n",
       "      <td>80:111</td>\n",
       "      <td>10.88</td>\n",
       "      <td>1.06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14300 rows × 271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        GAME_DATE HOME AWAY  AST _ewm10  BLK _ewm10  DREB _ewm10  \\\n",
       "0      28/10/2008  BOS  CLE   -0.053016    0.008363     0.014856   \n",
       "1      28/10/2008  CHI  MIL   -0.001185   -0.004342    -0.058237   \n",
       "2      28/10/2008  LAL  POR   -0.081911    0.001941     0.027199   \n",
       "3      29/10/2008  DET  IND    0.052314    0.020826    -0.020202   \n",
       "4      29/10/2008  GSW  NOP   -0.026685    0.038596     0.004095   \n",
       "...           ...  ...  ...         ...         ...          ...   \n",
       "14295  10/04/2022  NYK  TOR    0.035821    0.015852     0.037074   \n",
       "14296  10/04/2022  ORL  MIA   -0.004794    0.036993     0.051106   \n",
       "14297  10/04/2022  PHI  DET    0.045087   -0.011308     0.016990   \n",
       "14298  10/04/2022  PHX  SAC    0.080521   -0.009226     0.047192   \n",
       "14299  10/04/2022  POR  UTA    0.036937   -0.025378    -0.131900   \n",
       "\n",
       "       FG_PCT _ewm10  FG3_PCT _ewm10  FG3A _ewm10  FG3M _ewm10  ...  \\\n",
       "0          -0.000706        0.000401     0.096037     0.040449  ...   \n",
       "1          -0.000422       -0.001997    -0.150581    -0.082637  ...   \n",
       "2          -0.001031       -0.001619     0.030843    -0.018690  ...   \n",
       "3           0.000044        0.000531     0.045038     0.029248  ...   \n",
       "4           0.000155       -0.000702    -0.142057    -0.061073  ...   \n",
       "...              ...             ...          ...          ...  ...   \n",
       "14295      -0.000346        0.000882     0.100520     0.063328  ...   \n",
       "14296      -0.001918       -0.002143     0.085899    -0.050124  ...   \n",
       "14297       0.001253        0.001721    -0.060110     0.050316  ...   \n",
       "14298       0.000443        0.000586     0.027357     0.024687  ...   \n",
       "14299      -0.000616       -0.000499    -0.090065    -0.044900  ...   \n",
       "\n",
       "       OPP_PTS_OFF_TOV_ewm5ha  OPP_PTS_PAINT_ewm5ha  PTS_2ND_CHANCE_ewm5ha  \\\n",
       "0                    0.433684             -0.361584               0.104689   \n",
       "1                    0.120543             -0.110391               0.363791   \n",
       "2                   -0.056882              0.159378              -0.498689   \n",
       "3                   -0.008929              1.189835               0.620750   \n",
       "4                   -0.777967              0.603658              -0.257766   \n",
       "...                       ...                   ...                    ...   \n",
       "14295               -0.236713             -0.154263              -0.810998   \n",
       "14296               -0.372876              0.077874               0.597325   \n",
       "14297                0.554088             -0.275713               0.322300   \n",
       "14298                0.285610             -0.141892               0.227124   \n",
       "14299                1.102207              1.208529               1.235325   \n",
       "\n",
       "       PTS_FB_ewm5ha  PTS_OFF_TOV_ewm5ha  PTS_PAINT_ewm5ha    Score  Odds1  \\\n",
       "0          -0.785678           -0.016826         -0.015002    90:85   1.36   \n",
       "1           0.588124           -0.552351          1.246822   108:95   1.36   \n",
       "2          -3.364871           -0.313756         -0.855125    96:76   1.27   \n",
       "3           2.002133            1.740860          0.471794   100:94   1.13   \n",
       "4           0.099136           -0.461950         -0.713632  103:108   3.35   \n",
       "...              ...                 ...               ...      ...    ...   \n",
       "14295      -1.268378           -0.856542         -0.941926   105:94   1.96   \n",
       "14296      -0.290637           -0.696616          0.265701  125:111   3.41   \n",
       "14297      -0.649111           -0.162648          1.015744  118:106   1.37   \n",
       "14298       1.075718            0.597625          0.317031  109:116   1.19   \n",
       "14299       1.026042            0.564374          0.419334   80:111  10.88   \n",
       "\n",
       "       Odds2  Results  \n",
       "0       3.15      1.0  \n",
       "1       3.20      1.0  \n",
       "2       3.85      1.0  \n",
       "3       5.75      1.0  \n",
       "4       1.32      0.0  \n",
       "...      ...      ...  \n",
       "14295   1.89      1.0  \n",
       "14296   1.34      1.0  \n",
       "14297   3.24      1.0  \n",
       "14298   5.16      0.0  \n",
       "14299   1.06      0.0  \n",
       "\n",
       "[14300 rows x 271 columns]"
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NAME = \"264x32x16x1_MSE_sv{}\".format(int(time.time()))\n",
    "#log_dir = \"logs/fit/\" + NAME\n",
    "#tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "stats = pd.read_csv(r'Data\\final_dataset.csv')\n",
    "stats['Results'] = stats['Results'].astype('float32')\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968da41f",
   "metadata": {},
   "source": [
    "#### Slice stats into X and y. Split the data into training and test set (80/20) and normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "5545731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stats.iloc[:,3:-4]\n",
    "y = stats.iloc[:,-1:]\n",
    "random_state = 12\n",
    "#split in order, we don't want our model to predict outcomes with data that have not happened yet.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = False, random_state=random_state)\n",
    "X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)\n",
    "stats['Results'] = stats['Results'].astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23759326",
   "metadata": {},
   "source": [
    "### Define the custom loss functions\n",
    "\n",
    "##### BCE: Binary-cross entropy with added parameters to optimize our return on investment.\n",
    "\n",
    "$L(y\\hat, y) = -\\sum\\limits_{i=1}^{m} (Odds_{1i}*y_{i}-1) * log(Odds_{1i}*\\hat y_{i}-1) + (Odds_{2i}(1 - y_{i})-1) * log(Odds_{2i}*(1- \\hat y_{i}) -1)$\n",
    "\n",
    "Source: https://www.vantage-ai.com/en/blog/beating-the-bookies-with-machine-learning\n",
    "\n",
    "We will try to fit these loss function in a near future.\n",
    "\n",
    "##### MSE: Mean Squared Error with odds decorrelation\n",
    "\n",
    "$L(p\\hat, y)= \\frac{1}{N} \\sum\\limits_{i=1}^{N}(\\hat p_{i} - y_{i})^{2} - C * (\\hat p_{i} - \\frac {1}{Odds_{i}})^{2}$\n",
    "\n",
    "The first part $(\\hat p_{i} - y_{i})^{2}$ is the Mean Squared Error, the difference between the predicted outcome versus the actual aoutcome. For the second part, C is a constant that determines the significance of the decorrelation effect. $(\\hat p_{i} - \\frac {1}{Odds_{i}})^{2}$, $\\hat p_{i}$ is the predicted probability for the home team and $\\frac {1}{Odds_{i}}$ is the probability that the bookmakers gives to the home team victory.\n",
    "\n",
    "Source: Hubáček, Ondřej, Gustav Šourek, and Filip Železný. \"Exploiting sports-betting market using machine learning.\" International Journal of Forecasting 35.2 (2019): 783-796.\n",
    "\n",
    "Keras only allow the parameters y_pred and y_true in the loss functions, to make our custom loss function we pass a wrapper function with our extra parameter, the odds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "77f61eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "odds1 = stats.iloc[:, -3:-2].values\n",
    "odds1_prob = 1/odds1\n",
    "\n",
    "def coef_bce(y_pred,y_true, odds1, odds2):\n",
    "    return -1 * K.mean((odds1 * y_true -1) * K.log(odds1 * y_pred -1) + (odds2 * (1- y_true) -1) * K.log(odds2 * (1-y_pred)-1))\n",
    "\n",
    "def bce_custom(odds1, odds2):\n",
    "    def bce(y_pred, y_true):\n",
    "        return coef_bce(y_pred, y_true, odds1, odds2)\n",
    "    return bce\n",
    "\n",
    "#loss_bce = bce_custom(odds1, odds2)\n",
    "\n",
    "\n",
    "def coef_mse(y_pred, y_true, odds_game ):\n",
    "    #mse = K.square(y_pred - y_true)  #squared difference\n",
    "    #odds = -0.10 * K.square(y_pred - odds_game)   \n",
    "    #loss = K.mean(mse - odds , axis=-1) #mean over last dimension\n",
    "    #return loss\n",
    "    return K.mean(K.square(y_pred - y_true) +0.2 * K.square(y_pred- odds_game), axis=-1)\n",
    "\n",
    "def mse_custom(odds_game):\n",
    "    def mse( y_pred, y_true):\n",
    "        return coef_mse(y_pred, y_true, odds_game)\n",
    "    return mse\n",
    "\n",
    "loss_mse = mse_custom(odds1_prob)\n",
    "\n",
    "\n",
    "def mse_simple(y_true, y_pred):\n",
    "    mse = math_ops.squared_difference(y_pred, y_true) \n",
    "    loss = K.mean(mse, axis=-1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fb5df3",
   "metadata": {},
   "source": [
    "### Model Architecture:\n",
    "After configuring GridSearch, the best parameters where:\n",
    "- layers: 64x32 // Input is 264(n. of features) and output is 1. So (264 x 64 x 32 x 1)\n",
    "- epochs: 5\n",
    "- batch size: 3\n",
    "- regularisation: l2(0.01)\n",
    "- activation function: ReLU except output layer (sigmoid)\n",
    "- optimizer: Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "9161915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "11440/11440 [==============================] - 20s 2ms/step - loss: 0.2193 - accuracy: 0.6490 - val_loss: 0.2301 - val_accuracy: 0.6259\n",
      "Epoch 2/5\n",
      "11440/11440 [==============================] - 19s 2ms/step - loss: 0.2145 - accuracy: 0.6645 - val_loss: 0.2298 - val_accuracy: 0.6318\n",
      "Epoch 3/5\n",
      "11440/11440 [==============================] - 20s 2ms/step - loss: 0.2125 - accuracy: 0.6713 - val_loss: 0.2284 - val_accuracy: 0.6346\n",
      "Epoch 4/5\n",
      "11440/11440 [==============================] - 19s 2ms/step - loss: 0.2105 - accuracy: 0.6723 - val_loss: 0.2319 - val_accuracy: 0.6241\n",
      "Epoch 5/5\n",
      "11440/11440 [==============================] - 21s 2ms/step - loss: 0.2089 - accuracy: 0.6765 - val_loss: 0.2261 - val_accuracy: 0.6339\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x284ab5f8fd0>"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#opt = tf.keras.optimizers.Adam(clipnorm=0.3)\n",
    "#bias_regularizer=l2(0.01)\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "model.add(Dense(264, input_dim=264, kernel_initializer='normal', activation='relu',bias_regularizer=l2(0.01)))\n",
    "model.add(Dense(64, kernel_initializer='normal', activation='relu',bias_regularizer=l2(0.01)))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu',bias_regularizer=l2(0.01)))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "model.compile(optimizer='Adam', loss='MeanSquaredError', metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size= 1, epochs=5, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "ae6eafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_loss, val_acc = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eff2fd3b",
   "metadata": {},
   "source": [
    "### Retrieve the information attached to the predictions and  store the predictions\n",
    "\n",
    "We attach the prediction with the outcome. We also retrieve the infomration regarding the game such as the data, the teams, the score and the odds so we can later perform an Error analysis. We finally store the dataframe in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "f1875eec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test[:])\n",
    "label = y_test[:]\n",
    "prediction_l = prediction.tolist()\n",
    "pred =pd.DataFrame(prediction_l, columns=['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "d799fcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Results</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>HOME</th>\n",
       "      <th>AWAY</th>\n",
       "      <th>Odds1</th>\n",
       "      <th>Odds2</th>\n",
       "      <th>Score</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11440</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23/10/2019</td>\n",
       "      <td>ORL</td>\n",
       "      <td>CLE</td>\n",
       "      <td>1.20</td>\n",
       "      <td>4.92</td>\n",
       "      <td>94:85</td>\n",
       "      <td>0.664552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11441</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23/10/2019</td>\n",
       "      <td>PHI</td>\n",
       "      <td>BOS</td>\n",
       "      <td>1.42</td>\n",
       "      <td>3.01</td>\n",
       "      <td>107:93</td>\n",
       "      <td>0.390108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11442</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23/10/2019</td>\n",
       "      <td>PHX</td>\n",
       "      <td>SAC</td>\n",
       "      <td>1.89</td>\n",
       "      <td>1.96</td>\n",
       "      <td>124:95</td>\n",
       "      <td>0.546155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11443</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23/10/2019</td>\n",
       "      <td>POR</td>\n",
       "      <td>DEN</td>\n",
       "      <td>2.02</td>\n",
       "      <td>1.84</td>\n",
       "      <td>100:108</td>\n",
       "      <td>0.688613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11444</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23/10/2019</td>\n",
       "      <td>SAS</td>\n",
       "      <td>NYK</td>\n",
       "      <td>1.16</td>\n",
       "      <td>5.56</td>\n",
       "      <td>120:111</td>\n",
       "      <td>0.725813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2855</th>\n",
       "      <td>14295</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/04/2022</td>\n",
       "      <td>NYK</td>\n",
       "      <td>TOR</td>\n",
       "      <td>1.96</td>\n",
       "      <td>1.89</td>\n",
       "      <td>105:94</td>\n",
       "      <td>0.460038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2856</th>\n",
       "      <td>14296</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/04/2022</td>\n",
       "      <td>ORL</td>\n",
       "      <td>MIA</td>\n",
       "      <td>3.41</td>\n",
       "      <td>1.34</td>\n",
       "      <td>125:111</td>\n",
       "      <td>0.256844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2857</th>\n",
       "      <td>14297</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10/04/2022</td>\n",
       "      <td>PHI</td>\n",
       "      <td>DET</td>\n",
       "      <td>1.37</td>\n",
       "      <td>3.24</td>\n",
       "      <td>118:106</td>\n",
       "      <td>0.783105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2858</th>\n",
       "      <td>14298</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10/04/2022</td>\n",
       "      <td>PHX</td>\n",
       "      <td>SAC</td>\n",
       "      <td>1.19</td>\n",
       "      <td>5.16</td>\n",
       "      <td>109:116</td>\n",
       "      <td>0.738342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2859</th>\n",
       "      <td>14299</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10/04/2022</td>\n",
       "      <td>POR</td>\n",
       "      <td>UTA</td>\n",
       "      <td>10.88</td>\n",
       "      <td>1.06</td>\n",
       "      <td>80:111</td>\n",
       "      <td>0.315279</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2860 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Results   GAME_DATE HOME AWAY  Odds1  Odds2    Score  prediction\n",
       "0     11440      1.0  23/10/2019  ORL  CLE   1.20   4.92    94:85    0.664552\n",
       "1     11441      1.0  23/10/2019  PHI  BOS   1.42   3.01   107:93    0.390108\n",
       "2     11442      1.0  23/10/2019  PHX  SAC   1.89   1.96   124:95    0.546155\n",
       "3     11443      0.0  23/10/2019  POR  DEN   2.02   1.84  100:108    0.688613\n",
       "4     11444      1.0  23/10/2019  SAS  NYK   1.16   5.56  120:111    0.725813\n",
       "...     ...      ...         ...  ...  ...    ...    ...      ...         ...\n",
       "2855  14295      1.0  10/04/2022  NYK  TOR   1.96   1.89   105:94    0.460038\n",
       "2856  14296      1.0  10/04/2022  ORL  MIA   3.41   1.34  125:111    0.256844\n",
       "2857  14297      1.0  10/04/2022  PHI  DET   1.37   3.24  118:106    0.783105\n",
       "2858  14298      0.0  10/04/2022  PHX  SAC   1.19   5.16  109:116    0.738342\n",
       "2859  14299      0.0  10/04/2022  POR  UTA  10.88   1.06   80:111    0.315279\n",
       "\n",
       "[2860 rows x 9 columns]"
      ]
     },
     "execution_count": 181,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.reset_index\n",
    "index = stats[['GAME_DATE', 'HOME', 'AWAY','Odds1', 'Odds2', 'Score']]\n",
    "data = label.join(index)\n",
    "data.reset_index(inplace=True)\n",
    "pred_data = data.join(pred)\n",
    "pred_data.to_csv('predicted_data.csv')\n",
    "pred_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bafe570",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "\n",
    "We use the GridSearchCV from sklearn to find the parameters that best optimize our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d59f82ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3432/3432 [==============================] - 2s 667us/step - loss: 0.2227 - accuracy: 0.6481\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.2212 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 394us/step - loss: 0.2230 - accuracy: 0.6399\n",
      "3432/3432 [==============================] - 2s 615us/step - loss: 0.2221 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 334us/step - loss: 0.2222 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 616us/step - loss: 0.2225 - accuracy: 0.6467\n",
      "382/382 [==============================] - 0s 362us/step - loss: 0.2213 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 599us/step - loss: 0.2227 - accuracy: 0.6425\n",
      "382/382 [==============================] - 0s 390us/step - loss: 0.2210 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 2s 610us/step - loss: 0.2224 - accuracy: 0.6429\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2176 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 593us/step - loss: 0.2226 - accuracy: 0.6439\n",
      "382/382 [==============================] - 0s 426us/step - loss: 0.2238 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 667us/step - loss: 0.2237 - accuracy: 0.6429\n",
      "382/382 [==============================] - 0s 368us/step - loss: 0.2164 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 722us/step - loss: 0.2224 - accuracy: 0.6409\n",
      "382/382 [==============================] - 0s 408us/step - loss: 0.2154 - accuracy: 0.6678\n",
      "3432/3432 [==============================] - 2s 593us/step - loss: 0.2227 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 392us/step - loss: 0.2280 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 2s 592us/step - loss: 0.2224 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 349us/step - loss: 0.2196 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 604us/step - loss: 0.2223 - accuracy: 0.6483\n",
      "382/382 [==============================] - 0s 360us/step - loss: 0.2209 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 580us/step - loss: 0.2215 - accuracy: 0.64700s - loss: 0.2209 - accuracy: 0.\n",
      "382/382 [==============================] - 0s 355us/step - loss: 0.2236 - accuracy: 0.6425\n",
      "3432/3432 [==============================] - 2s 579us/step - loss: 0.2220 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 351us/step - loss: 0.2227 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 584us/step - loss: 0.2229 - accuracy: 0.6451\n",
      "382/382 [==============================] - 0s 351us/step - loss: 0.2200 - accuracy: 0.6407\n",
      "3432/3432 [==============================] - 2s 676us/step - loss: 0.2232 - accuracy: 0.6420\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2167 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 577us/step - loss: 0.2220 - accuracy: 0.6439\n",
      "382/382 [==============================] - 0s 375us/step - loss: 0.2222 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 2s 588us/step - loss: 0.2231 - accuracy: 0.6453\n",
      "382/382 [==============================] - 0s 373us/step - loss: 0.2189 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 597us/step - loss: 0.2230 - accuracy: 0.6460\n",
      "382/382 [==============================] - 0s 390us/step - loss: 0.2175 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 595us/step - loss: 0.2223 - accuracy: 0.6443\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.2577 - accuracy: 0.3333WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 394us/step - loss: 0.2181 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 3s 751us/step - loss: 0.2236 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 407us/step - loss: 0.2166 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 2s 696us/step - loss: 0.2222 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 417us/step - loss: 0.2227 - accuracy: 0.6337\n",
      "3432/3432 [==============================] - 2s 680us/step - loss: 0.2223 - accuracy: 0.6475\n",
      "382/382 [==============================] - 0s 403us/step - loss: 0.2228 - accuracy: 0.6372\n",
      "3432/3432 [==============================] - 2s 608us/step - loss: 0.2225 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 349us/step - loss: 0.2246 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 680us/step - loss: 0.2219 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 493us/step - loss: 0.2226 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 2s 718us/step - loss: 0.2230 - accuracy: 0.6411\n",
      "382/382 [==============================] - 0s 387us/step - loss: 0.2169 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 640us/step - loss: 0.2224 - accuracy: 0.6468\n",
      "382/382 [==============================] - 0s 361us/step - loss: 0.2276 - accuracy: 0.6425\n",
      "3432/3432 [==============================] - 2s 596us/step - loss: 0.2230 - accuracy: 0.6490\n",
      "382/382 [==============================] - 0s 364us/step - loss: 0.2164 - accuracy: 0.6678\n",
      "3432/3432 [==============================] - 2s 591us/step - loss: 0.2230 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 464us/step - loss: 0.2150 - accuracy: 0.6687\n",
      "3432/3432 [==============================] - 2s 613us/step - loss: 0.2219 - accuracy: 0.6465\n",
      "382/382 [==============================] - 0s 371us/step - loss: 0.2216 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 620us/step - loss: 0.2228 - accuracy: 0.6435\n",
      "382/382 [==============================] - 0s 345us/step - loss: 0.2157 - accuracy: 0.6600\n",
      "3432/3432 [==============================] - 2s 630us/step - loss: 0.2225 - accuracy: 0.6466\n",
      "382/382 [==============================] - 0s 460us/step - loss: 0.2255 - accuracy: 0.6355\n",
      "3432/3432 [==============================] - 2s 696us/step - loss: 0.2219 - accuracy: 0.6487\n",
      "382/382 [==============================] - 0s 444us/step - loss: 0.2247 - accuracy: 0.6381\n",
      "3432/3432 [==============================] - 2s 672us/step - loss: 0.2226 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 359us/step - loss: 0.2203 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 2s 581us/step - loss: 0.2221 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 362us/step - loss: 0.2186 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 672us/step - loss: 0.2227 - accuracy: 0.6454\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.0929 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 490us/step - loss: 0.2188 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 593us/step - loss: 0.2222 - accuracy: 0.6441\n",
      "382/382 [==============================] - 0s 376us/step - loss: 0.2278 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 2s 586us/step - loss: 0.2229 - accuracy: 0.6449\n",
      "382/382 [==============================] - 0s 377us/step - loss: 0.2163 - accuracy: 0.6661\n",
      "3432/3432 [==============================] - 2s 598us/step - loss: 0.2231 - accuracy: 0.6445\n",
      "382/382 [==============================] - 0s 373us/step - loss: 0.2176 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 2s 600us/step - loss: 0.2225 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 350us/step - loss: 0.2225 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 595us/step - loss: 0.2226 - accuracy: 0.6488\n",
      "382/382 [==============================] - 0s 368us/step - loss: 0.2166 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 652us/step - loss: 0.2225 - accuracy: 0.6422\n",
      "382/382 [==============================] - 0s 459us/step - loss: 0.2230 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 709us/step - loss: 0.2221 - accuracy: 0.6482\n",
      "382/382 [==============================] - 0s 408us/step - loss: 0.2267 - accuracy: 0.6355\n",
      "3432/3432 [==============================] - 2s 636us/step - loss: 0.2222 - accuracy: 0.6413\n",
      "382/382 [==============================] - 0s 361us/step - loss: 0.2238 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 645us/step - loss: 0.2225 - accuracy: 0.64600s - loss: 0.2231 - ac\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.2653 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 401us/step - loss: 0.2203 - accuracy: 0.6355\n",
      "3432/3432 [==============================] - 2s 593us/step - loss: 0.2234 - accuracy: 0.6435\n",
      "382/382 [==============================] - 0s 396us/step - loss: 0.2168 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 2s 618us/step - loss: 0.2219 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 399us/step - loss: 0.2218 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 637us/step - loss: 0.2229 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 369us/step - loss: 0.2146 - accuracy: 0.6643\n",
      "3432/3432 [==============================] - 2s 644us/step - loss: 0.2229 - accuracy: 0.6432\n",
      "382/382 [==============================] - 0s 393us/step - loss: 0.2152 - accuracy: 0.6696\n",
      "3432/3432 [==============================] - 2s 601us/step - loss: 0.2227 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2220 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 595us/step - loss: 0.2229 - accuracy: 0.6478\n",
      "382/382 [==============================] - 0s 383us/step - loss: 0.2160 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 640us/step - loss: 0.2224 - accuracy: 0.6445\n",
      "382/382 [==============================] - 0s 376us/step - loss: 0.2212 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 596us/step - loss: 0.2216 - accuracy: 0.6497\n",
      "382/382 [==============================] - 0s 361us/step - loss: 0.2215 - accuracy: 0.6407\n",
      "3432/3432 [==============================] - 2s 636us/step - loss: 0.2220 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 392us/step - loss: 0.2228 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 597us/step - loss: 0.2217 - accuracy: 0.6445\n",
      "382/382 [==============================] - 0s 401us/step - loss: 0.2208 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 2s 581us/step - loss: 0.2232 - accuracy: 0.6387\n",
      "382/382 [==============================] - 0s 334us/step - loss: 0.2145 - accuracy: 0.6600\n",
      "3432/3432 [==============================] - 2s 603us/step - loss: 0.2220 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 340us/step - loss: 0.2230 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 2s 615us/step - loss: 0.2232 - accuracy: 0.6423\n",
      "382/382 [==============================] - 0s 344us/step - loss: 0.2178 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 597us/step - loss: 0.2230 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 375us/step - loss: 0.2175 - accuracy: 0.6696\n",
      "3432/3432 [==============================] - 2s 620us/step - loss: 0.2223 - accuracy: 0.6408\n",
      "382/382 [==============================] - 0s 362us/step - loss: 0.2189 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 2s 599us/step - loss: 0.2227 - accuracy: 0.6492\n",
      "382/382 [==============================] - 0s 345us/step - loss: 0.2156 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 2s 600us/step - loss: 0.2222 - accuracy: 0.6436\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.1694 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 364us/step - loss: 0.2232 - accuracy: 0.6372\n",
      "3432/3432 [==============================] - 2s 632us/step - loss: 0.2221 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 360us/step - loss: 0.2243 - accuracy: 0.6250\n",
      "3432/3432 [==============================] - 2s 606us/step - loss: 0.2219 - accuracy: 0.6502\n",
      "382/382 [==============================] - 0s 353us/step - loss: 0.2243 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 614us/step - loss: 0.2221 - accuracy: 0.6438\n",
      "382/382 [==============================] - 0s 370us/step - loss: 0.2209 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 2s 614us/step - loss: 0.2232 - accuracy: 0.6431\n",
      "382/382 [==============================] - 0s 423us/step - loss: 0.2168 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 592us/step - loss: 0.2222 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 359us/step - loss: 0.2245 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 616us/step - loss: 0.2229 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 368us/step - loss: 0.2142 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 2s 596us/step - loss: 0.2232 - accuracy: 0.6431\n",
      "382/382 [==============================] - 0s 358us/step - loss: 0.2167 - accuracy: 0.6661\n",
      "3432/3432 [==============================] - 2s 589us/step - loss: 0.2222 - accuracy: 0.6458\n",
      "382/382 [==============================] - 0s 486us/step - loss: 0.2212 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 696us/step - loss: 0.2228 - accuracy: 0.6430\n",
      "382/382 [==============================] - 0s 345us/step - loss: 0.2166 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 2s 619us/step - loss: 0.2218 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 400us/step - loss: 0.2216 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 2s 595us/step - loss: 0.2219 - accuracy: 0.6467\n",
      "382/382 [==============================] - 0s 391us/step - loss: 0.2270 - accuracy: 0.6320\n",
      "3432/3432 [==============================] - 2s 596us/step - loss: 0.2224 - accuracy: 0.6427\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.2627 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0156s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 370us/step - loss: 0.2220 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 589us/step - loss: 0.2228 - accuracy: 0.6457\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2201 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 2s 594us/step - loss: 0.2229 - accuracy: 0.6489\n",
      "382/382 [==============================] - 0s 353us/step - loss: 0.2163 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 620us/step - loss: 0.2223 - accuracy: 0.6427\n",
      "382/382 [==============================] - 0s 368us/step - loss: 0.2211 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 624us/step - loss: 0.2234 - accuracy: 0.6426\n",
      "382/382 [==============================] - 0s 399us/step - loss: 0.2165 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 601us/step - loss: 0.2228 - accuracy: 0.6448\n",
      "382/382 [==============================] - 0s 354us/step - loss: 0.2141 - accuracy: 0.6687\n",
      "3432/3432 [==============================] - 2s 643us/step - loss: 0.2226 - accuracy: 0.6459\n",
      "382/382 [==============================] - 0s 436us/step - loss: 0.2200 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 625us/step - loss: 0.2233 - accuracy: 0.6453\n",
      "382/382 [==============================] - 0s 389us/step - loss: 0.2156 - accuracy: 0.6486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3432/3432 [==============================] - 2s 587us/step - loss: 0.2227 - accuracy: 0.6399\n",
      "382/382 [==============================] - 0s 376us/step - loss: 0.2227 - accuracy: 0.6390\n",
      "3432/3432 [==============================] - 2s 592us/step - loss: 0.2223 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 353us/step - loss: 0.2232 - accuracy: 0.6337\n",
      "3432/3432 [==============================] - 2s 591us/step - loss: 0.2228 - accuracy: 0.6407\n",
      "382/382 [==============================] - 0s 360us/step - loss: 0.2226 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 2s 578us/step - loss: 0.2220 - accuracy: 0.6466\n",
      "382/382 [==============================] - 0s 341us/step - loss: 0.2223 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 2s 571us/step - loss: 0.2228 - accuracy: 0.6461\n",
      "382/382 [==============================] - 0s 381us/step - loss: 0.2152 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 580us/step - loss: 0.2224 - accuracy: 0.6462\n",
      "382/382 [==============================] - 0s 336us/step - loss: 0.2197 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 2s 576us/step - loss: 0.2228 - accuracy: 0.6413\n",
      "382/382 [==============================] - 0s 352us/step - loss: 0.2144 - accuracy: 0.6626\n",
      "3432/3432 [==============================] - 2s 581us/step - loss: 0.2234 - accuracy: 0.6415\n",
      "382/382 [==============================] - 0s 362us/step - loss: 0.2146 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 588us/step - loss: 0.2225 - accuracy: 0.6405\n",
      "382/382 [==============================] - 0s 365us/step - loss: 0.2200 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 603us/step - loss: 0.2228 - accuracy: 0.6442\n",
      "382/382 [==============================] - 0s 359us/step - loss: 0.2149 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 589us/step - loss: 0.2216 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 364us/step - loss: 0.2255 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 583us/step - loss: 0.2227 - accuracy: 0.6488\n",
      "382/382 [==============================] - 0s 419us/step - loss: 0.2269 - accuracy: 0.6276\n",
      "3432/3432 [==============================] - 2s 640us/step - loss: 0.2219 - accuracy: 0.6467\n",
      "382/382 [==============================] - 0s 387us/step - loss: 0.2233 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 648us/step - loss: 0.2222 - accuracy: 0.6484\n",
      "382/382 [==============================] - 0s 357us/step - loss: 0.2261 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 683us/step - loss: 0.2228 - accuracy: 0.6453\n",
      "382/382 [==============================] - 0s 340us/step - loss: 0.2155 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 2s 628us/step - loss: 0.2228 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 353us/step - loss: 0.2215 - accuracy: 0.6381\n",
      "3432/3432 [==============================] - 2s 682us/step - loss: 0.2230 - accuracy: 0.6442\n",
      "382/382 [==============================] - 0s 513us/step - loss: 0.2153 - accuracy: 0.6713\n",
      "3432/3432 [==============================] - 2s 623us/step - loss: 0.2232 - accuracy: 0.6453\n",
      "382/382 [==============================] - 0s 369us/step - loss: 0.2151 - accuracy: 0.6678\n",
      "3432/3432 [==============================] - 2s 620us/step - loss: 0.2226 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 530us/step - loss: 0.2203 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 582us/step - loss: 0.2229 - accuracy: 0.6449\n",
      "382/382 [==============================] - 0s 353us/step - loss: 0.2174 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 2s 666us/step - loss: 0.2227 - accuracy: 0.6449\n",
      "382/382 [==============================] - 0s 364us/step - loss: 0.2187 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 589us/step - loss: 0.2224 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 392us/step - loss: 0.2225 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 587us/step - loss: 0.2226 - accuracy: 0.6402\n",
      "382/382 [==============================] - 0s 380us/step - loss: 0.2224 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 582us/step - loss: 0.2225 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 385us/step - loss: 0.2200 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 584us/step - loss: 0.2227 - accuracy: 0.6481\n",
      "382/382 [==============================] - 0s 355us/step - loss: 0.2199 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 584us/step - loss: 0.2224 - accuracy: 0.6457\n",
      "382/382 [==============================] - 0s 392us/step - loss: 0.2228 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 2s 587us/step - loss: 0.2227 - accuracy: 0.6419\n",
      "382/382 [==============================] - 0s 390us/step - loss: 0.2203 - accuracy: 0.6696\n",
      "3432/3432 [==============================] - 2s 583us/step - loss: 0.2226 - accuracy: 0.6458\n",
      "382/382 [==============================] - 0s 387us/step - loss: 0.2175 - accuracy: 0.6626\n",
      "3432/3432 [==============================] - 2s 602us/step - loss: 0.2221 - accuracy: 0.6452\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.2609 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0156s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 368us/step - loss: 0.2216 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 2s 592us/step - loss: 0.2230 - accuracy: 0.6448\n",
      "382/382 [==============================] - 0s 381us/step - loss: 0.2202 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 575us/step - loss: 0.2219 - accuracy: 0.6445\n",
      "382/382 [==============================] - 0s 370us/step - loss: 0.2218 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 594us/step - loss: 0.2215 - accuracy: 0.6463\n",
      "382/382 [==============================] - 0s 375us/step - loss: 0.2287 - accuracy: 0.6276\n",
      "3432/3432 [==============================] - 2s 598us/step - loss: 0.2228 - accuracy: 0.6451\n",
      "382/382 [==============================] - 0s 382us/step - loss: 0.2214 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 603us/step - loss: 0.2220 - accuracy: 0.6475\n",
      "382/382 [==============================] - 0s 345us/step - loss: 0.2240 - accuracy: 0.6407\n",
      "3432/3432 [==============================] - 2s 610us/step - loss: 0.2226 - accuracy: 0.6451\n",
      "382/382 [==============================] - 0s 377us/step - loss: 0.2180 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 593us/step - loss: 0.2224 - accuracy: 0.6425\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2264 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 606us/step - loss: 0.2230 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 356us/step - loss: 0.2151 - accuracy: 0.6617\n",
      "3432/3432 [==============================] - 2s 621us/step - loss: 0.2233 - accuracy: 0.6435\n",
      "382/382 [==============================] - 0s 374us/step - loss: 0.2171 - accuracy: 0.6626\n",
      "3432/3432 [==============================] - 2s 603us/step - loss: 0.2223 - accuracy: 0.6416\n",
      "382/382 [==============================] - 0s 361us/step - loss: 0.2223 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 588us/step - loss: 0.2232 - accuracy: 0.6462\n",
      "382/382 [==============================] - 0s 325us/step - loss: 0.2210 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 617us/step - loss: 0.2221 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 411us/step - loss: 0.2229 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 613us/step - loss: 0.2224 - accuracy: 0.6475\n",
      "382/382 [==============================] - 0s 357us/step - loss: 0.2224 - accuracy: 0.6355\n",
      "3432/3432 [==============================] - 2s 614us/step - loss: 0.2228 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 390us/step - loss: 0.2233 - accuracy: 0.6372\n",
      "3432/3432 [==============================] - 2s 623us/step - loss: 0.2225 - accuracy: 0.6464\n",
      "382/382 [==============================] - 0s 349us/step - loss: 0.2283 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 2s 613us/step - loss: 0.2229 - accuracy: 0.6428\n",
      "382/382 [==============================] - 0s 378us/step - loss: 0.2183 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 611us/step - loss: 0.2223 - accuracy: 0.6453\n",
      "382/382 [==============================] - 0s 342us/step - loss: 0.2209 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 2s 597us/step - loss: 0.2227 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 364us/step - loss: 0.2157 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 601us/step - loss: 0.2231 - accuracy: 0.6441\n",
      "382/382 [==============================] - 0s 411us/step - loss: 0.2147 - accuracy: 0.6705\n",
      "3432/3432 [==============================] - 2s 607us/step - loss: 0.2225 - accuracy: 0.6433\n",
      "382/382 [==============================] - 0s 395us/step - loss: 0.2206 - accuracy: 0.6407\n",
      "3432/3432 [==============================] - 2s 608us/step - loss: 0.2228 - accuracy: 0.6416\n",
      "382/382 [==============================] - 0s 363us/step - loss: 0.2157 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 601us/step - loss: 0.2224 - accuracy: 0.6484\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.1928 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0156s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 370us/step - loss: 0.2213 - accuracy: 0.6399\n",
      "3432/3432 [==============================] - 2s 598us/step - loss: 0.2225 - accuracy: 0.6475\n",
      "382/382 [==============================] - 0s 341us/step - loss: 0.2276 - accuracy: 0.6329\n",
      "3432/3432 [==============================] - 2s 605us/step - loss: 0.2224 - accuracy: 0.6454\n",
      "382/382 [==============================] - 0s 336us/step - loss: 0.2230 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 607us/step - loss: 0.2223 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 383us/step - loss: 0.2228 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 2s 604us/step - loss: 0.2231 - accuracy: 0.6460\n",
      "382/382 [==============================] - 0s 361us/step - loss: 0.2162 - accuracy: 0.6600\n",
      "3432/3432 [==============================] - 2s 607us/step - loss: 0.2219 - accuracy: 0.6458\n",
      "382/382 [==============================] - 0s 385us/step - loss: 0.2182 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 606us/step - loss: 0.2228 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 377us/step - loss: 0.2199 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 609us/step - loss: 0.2231 - accuracy: 0.6439\n",
      "382/382 [==============================] - 0s 432us/step - loss: 0.2194 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 666us/step - loss: 0.2222 - accuracy: 0.6457\n",
      "382/382 [==============================] - 0s 393us/step - loss: 0.2213 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 667us/step - loss: 0.2220 - accuracy: 0.6478\n",
      "382/382 [==============================] - 0s 406us/step - loss: 0.2149 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 617us/step - loss: 0.2222 - accuracy: 0.6462\n",
      "382/382 [==============================] - 0s 335us/step - loss: 0.2204 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 634us/step - loss: 0.2220 - accuracy: 0.6492\n",
      "382/382 [==============================] - 0s 364us/step - loss: 0.2244 - accuracy: 0.6294\n",
      "3432/3432 [==============================] - 2s 616us/step - loss: 0.2221 - accuracy: 0.6476\n",
      "382/382 [==============================] - 0s 368us/step - loss: 0.2210 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 707us/step - loss: 0.2227 - accuracy: 0.6489\n",
      "382/382 [==============================] - 0s 434us/step - loss: 0.2220 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 681us/step - loss: 0.2227 - accuracy: 0.6437\n",
      "382/382 [==============================] - 0s 384us/step - loss: 0.2159 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 717us/step - loss: 0.2221 - accuracy: 0.6495\n",
      "382/382 [==============================] - 0s 478us/step - loss: 0.2211 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 2s 615us/step - loss: 0.2231 - accuracy: 0.6413\n",
      "382/382 [==============================] - 0s 386us/step - loss: 0.2188 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 669us/step - loss: 0.2232 - accuracy: 0.6433\n",
      "382/382 [==============================] - 0s 429us/step - loss: 0.2152 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 618us/step - loss: 0.2233 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 350us/step - loss: 0.2213 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 620us/step - loss: 0.2234 - accuracy: 0.6460\n",
      "382/382 [==============================] - 0s 374us/step - loss: 0.2190 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 616us/step - loss: 0.2222 - accuracy: 0.6464\n",
      "382/382 [==============================] - 0s 486us/step - loss: 0.2218 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 631us/step - loss: 0.2218 - accuracy: 0.6501\n",
      "382/382 [==============================] - 0s 390us/step - loss: 0.2232 - accuracy: 0.6285\n",
      "3432/3432 [==============================] - 2s 677us/step - loss: 0.2226 - accuracy: 0.6451\n",
      "382/382 [==============================] - 0s 389us/step - loss: 0.2232 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 3s 743us/step - loss: 0.2231 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 412us/step - loss: 0.2222 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 623us/step - loss: 0.2235 - accuracy: 0.6427\n",
      "382/382 [==============================] - 0s 368us/step - loss: 0.2175 - accuracy: 0.6652\n",
      "3432/3432 [==============================] - 2s 632us/step - loss: 0.2225 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 387us/step - loss: 0.2221 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 624us/step - loss: 0.2232 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 389us/step - loss: 0.2156 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 2s 643us/step - loss: 0.2236 - accuracy: 0.6399\n",
      "382/382 [==============================] - 0s 368us/step - loss: 0.2203 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 2s 629us/step - loss: 0.2226 - accuracy: 0.6414\n",
      "382/382 [==============================] - 0s 371us/step - loss: 0.2206 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 2s 629us/step - loss: 0.2225 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 406us/step - loss: 0.2167 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 620us/step - loss: 0.2225 - accuracy: 0.6445\n",
      "382/382 [==============================] - 0s 393us/step - loss: 0.2231 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 3s 758us/step - loss: 0.2217 - accuracy: 0.6471\n",
      "382/382 [==============================] - 0s 347us/step - loss: 0.2243 - accuracy: 0.6329\n",
      "3432/3432 [==============================] - 2s 661us/step - loss: 0.2221 - accuracy: 0.6479\n",
      "382/382 [==============================] - 0s 372us/step - loss: 0.2220 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 618us/step - loss: 0.2225 - accuracy: 0.6481\n",
      "382/382 [==============================] - 0s 385us/step - loss: 0.2216 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 648us/step - loss: 0.2225 - accuracy: 0.6461\n",
      "382/382 [==============================] - 0s 386us/step - loss: 0.2190 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 620us/step - loss: 0.2227 - accuracy: 0.6454\n",
      "382/382 [==============================] - 0s 390us/step - loss: 0.2205 - accuracy: 0.6547\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3432/3432 [==============================] - 3s 742us/step - loss: 0.2227 - accuracy: 0.6476\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2148 - accuracy: 0.6600\n",
      "3432/3432 [==============================] - 2s 678us/step - loss: 0.2228 - accuracy: 0.6460\n",
      "382/382 [==============================] - 0s 405us/step - loss: 0.2170 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 3s 751us/step - loss: 0.2224 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 472us/step - loss: 0.2207 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 2s 705us/step - loss: 0.2231 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 405us/step - loss: 0.2177 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 655us/step - loss: 0.2225 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 388us/step - loss: 0.2203 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 2s 613us/step - loss: 0.2226 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 361us/step - loss: 0.2253 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 2s 647us/step - loss: 0.2220 - accuracy: 0.6451\n",
      "382/382 [==============================] - 0s 346us/step - loss: 0.2216 - accuracy: 0.6372\n",
      "3432/3432 [==============================] - 2s 621us/step - loss: 0.2225 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 370us/step - loss: 0.2201 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 639us/step - loss: 0.2228 - accuracy: 0.6429\n",
      "382/382 [==============================] - 0s 376us/step - loss: 0.2148 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 2s 640us/step - loss: 0.2224 - accuracy: 0.6448\n",
      "382/382 [==============================] - 0s 467us/step - loss: 0.2182 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 632us/step - loss: 0.2226 - accuracy: 0.6413\n",
      "382/382 [==============================] - 0s 391us/step - loss: 0.2154 - accuracy: 0.6731\n",
      "3432/3432 [==============================] - 2s 676us/step - loss: 0.2237 - accuracy: 0.6387\n",
      "382/382 [==============================] - 0s 385us/step - loss: 0.2164 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 2s 640us/step - loss: 0.2228 - accuracy: 0.6459\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2202 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 2s 631us/step - loss: 0.2228 - accuracy: 0.6458\n",
      "382/382 [==============================] - 0s 347us/step - loss: 0.2178 - accuracy: 0.6407\n",
      "3432/3432 [==============================] - 2s 649us/step - loss: 0.2225 - accuracy: 0.6474\n",
      "382/382 [==============================] - 0s 381us/step - loss: 0.2206 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 635us/step - loss: 0.2226 - accuracy: 0.6421\n",
      "382/382 [==============================] - 0s 368us/step - loss: 0.2238 - accuracy: 0.6329\n",
      "3432/3432 [==============================] - 2s 648us/step - loss: 0.2224 - accuracy: 0.6462\n",
      "382/382 [==============================] - 0s 363us/step - loss: 0.2232 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 627us/step - loss: 0.2221 - accuracy: 0.6439\n",
      "382/382 [==============================] - 0s 392us/step - loss: 0.2240 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 2s 675us/step - loss: 0.2230 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 349us/step - loss: 0.2167 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 2s 722us/step - loss: 0.2228 - accuracy: 0.6426\n",
      "382/382 [==============================] - 0s 408us/step - loss: 0.2207 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 2s 658us/step - loss: 0.2227 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 359us/step - loss: 0.2172 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 2s 605us/step - loss: 0.2233 - accuracy: 0.6415\n",
      "382/382 [==============================] - 0s 357us/step - loss: 0.2244 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 2s 640us/step - loss: 0.2230 - accuracy: 0.6459\n",
      "382/382 [==============================] - 0s 369us/step - loss: 0.2190 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 639us/step - loss: 0.2228 - accuracy: 0.64820s - loss: 0.2226 - accuracy: 0.\n",
      "382/382 [==============================] - 0s 346us/step - loss: 0.2145 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 623us/step - loss: 0.2224 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 387us/step - loss: 0.2226 - accuracy: 0.6364\n",
      "3432/3432 [==============================] - 2s 629us/step - loss: 0.2224 - accuracy: 0.6503\n",
      "382/382 [==============================] - 0s 442us/step - loss: 0.2245 - accuracy: 0.6390\n",
      "3432/3432 [==============================] - 3s 729us/step - loss: 0.2221 - accuracy: 0.6458\n",
      "382/382 [==============================] - 0s 371us/step - loss: 0.2224 - accuracy: 0.6399\n",
      "3432/3432 [==============================] - 2s 639us/step - loss: 0.2231 - accuracy: 0.6433\n",
      "382/382 [==============================] - 0s 393us/step - loss: 0.2244 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 2s 645us/step - loss: 0.2228 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 384us/step - loss: 0.2206 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 2s 631us/step - loss: 0.2217 - accuracy: 0.6479\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.2120 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 389us/step - loss: 0.2204 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 3s 771us/step - loss: 0.2231 - accuracy: 0.6430\n",
      "382/382 [==============================] - 0s 387us/step - loss: 0.2163 - accuracy: 0.6687\n",
      "3432/3432 [==============================] - 3s 792us/step - loss: 0.2230 - accuracy: 0.6458\n",
      "382/382 [==============================] - 0s 467us/step - loss: 0.2191 - accuracy: 0.6652\n",
      "3432/3432 [==============================] - 3s 740us/step - loss: 0.2221 - accuracy: 0.6463\n",
      "382/382 [==============================] - 0s 422us/step - loss: 0.2193 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 3s 734us/step - loss: 0.2233 - accuracy: 0.6463\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.0952 - accuracy: 1.0000WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0010s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 416us/step - loss: 0.2203 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 3s 730us/step - loss: 0.2220 - accuracy: 0.6443\n",
      "382/382 [==============================] - 0s 355us/step - loss: 0.2283 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 654us/step - loss: 0.2223 - accuracy: 0.6463\n",
      "382/382 [==============================] - 0s 386us/step - loss: 0.2260 - accuracy: 0.6346\n",
      "3432/3432 [==============================] - 2s 657us/step - loss: 0.2221 - accuracy: 0.6455\n",
      "382/382 [==============================] - 0s 395us/step - loss: 0.2223 - accuracy: 0.6661\n",
      "3432/3432 [==============================] - 2s 722us/step - loss: 0.2226 - accuracy: 0.6488\n",
      "382/382 [==============================] - 0s 374us/step - loss: 0.2198 - accuracy: 0.6381\n",
      "3432/3432 [==============================] - 3s 778us/step - loss: 0.2235 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 382us/step - loss: 0.2162 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 643us/step - loss: 0.2217 - accuracy: 0.6482\n",
      "382/382 [==============================] - 0s 355us/step - loss: 0.2212 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 3s 740us/step - loss: 0.2227 - accuracy: 0.6452\n",
      "382/382 [==============================] - 0s 412us/step - loss: 0.2163 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 648us/step - loss: 0.2233 - accuracy: 0.6441\n",
      "382/382 [==============================] - 0s 435us/step - loss: 0.2183 - accuracy: 0.6652\n",
      "3432/3432 [==============================] - 2s 655us/step - loss: 0.2220 - accuracy: 0.6454\n",
      "382/382 [==============================] - 0s 362us/step - loss: 0.2240 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 2s 645us/step - loss: 0.2234 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 397us/step - loss: 0.2169 - accuracy: 0.6390\n",
      "3432/3432 [==============================] - 2s 636us/step - loss: 0.2224 - accuracy: 0.6473\n",
      "382/382 [==============================] - 0s 397us/step - loss: 0.2214 - accuracy: 0.6372\n",
      "3432/3432 [==============================] - 2s 627us/step - loss: 0.2220 - accuracy: 0.6488\n",
      "382/382 [==============================] - 0s 372us/step - loss: 0.2240 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 2s 624us/step - loss: 0.2219 - accuracy: 0.6455\n",
      "382/382 [==============================] - 0s 368us/step - loss: 0.2253 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 2s 620us/step - loss: 0.2224 - accuracy: 0.6480\n",
      "382/382 [==============================] - 0s 390us/step - loss: 0.2224 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 2s 620us/step - loss: 0.2232 - accuracy: 0.6442\n",
      "382/382 [==============================] - 0s 367us/step - loss: 0.2159 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 2s 637us/step - loss: 0.2224 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 407us/step - loss: 0.2226 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 646us/step - loss: 0.2232 - accuracy: 0.6424\n",
      "382/382 [==============================] - 0s 374us/step - loss: 0.2146 - accuracy: 0.6740\n",
      "3432/3432 [==============================] - 2s 646us/step - loss: 0.2227 - accuracy: 0.6454\n",
      "382/382 [==============================] - 0s 369us/step - loss: 0.2156 - accuracy: 0.6643\n",
      "3432/3432 [==============================] - 2s 629us/step - loss: 0.2221 - accuracy: 0.6465\n",
      "382/382 [==============================] - 0s 402us/step - loss: 0.2240 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 623us/step - loss: 0.2234 - accuracy: 0.6439\n",
      "382/382 [==============================] - 0s 398us/step - loss: 0.2162 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 629us/step - loss: 0.2224 - accuracy: 0.6437\n",
      "382/382 [==============================] - 0s 378us/step - loss: 0.2194 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 628us/step - loss: 0.2220 - accuracy: 0.6455\n",
      "382/382 [==============================] - 0s 359us/step - loss: 0.2239 - accuracy: 0.6294\n",
      "3432/3432 [==============================] - 2s 629us/step - loss: 0.2221 - accuracy: 0.6430\n",
      "382/382 [==============================] - 0s 373us/step - loss: 0.2237 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 637us/step - loss: 0.2229 - accuracy: 0.6462\n",
      "382/382 [==============================] - 0s 406us/step - loss: 0.2203 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 2s 617us/step - loss: 0.2236 - accuracy: 0.6422\n",
      "382/382 [==============================] - 0s 360us/step - loss: 0.2161 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 2s 626us/step - loss: 0.2223 - accuracy: 0.6505\n",
      "382/382 [==============================] - 0s 371us/step - loss: 0.2220 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 628us/step - loss: 0.2233 - accuracy: 0.6426\n",
      "382/382 [==============================] - 0s 360us/step - loss: 0.2170 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 620us/step - loss: 0.2236 - accuracy: 0.6407\n",
      "382/382 [==============================] - 0s 376us/step - loss: 0.2161 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 613us/step - loss: 0.2221 - accuracy: 0.6433\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.2493 - accuracy: 0.3333WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0156s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 394us/step - loss: 0.2207 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 635us/step - loss: 0.2232 - accuracy: 0.6441\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2226 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 2s 629us/step - loss: 0.2224 - accuracy: 0.6480\n",
      "382/382 [==============================] - 0s 406us/step - loss: 0.2207 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 2s 631us/step - loss: 0.2228 - accuracy: 0.6480\n",
      "382/382 [==============================] - 0s 400us/step - loss: 0.2293 - accuracy: 0.6346\n",
      "3432/3432 [==============================] - 2s 620us/step - loss: 0.2226 - accuracy: 0.6449\n",
      "382/382 [==============================] - 0s 390us/step - loss: 0.2208 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 627us/step - loss: 0.2221 - accuracy: 0.6499\n",
      "382/382 [==============================] - 0s 407us/step - loss: 0.2186 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 2s 610us/step - loss: 0.2231 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 389us/step - loss: 0.2173 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 716us/step - loss: 0.2229 - accuracy: 0.6451\n",
      "382/382 [==============================] - 0s 373us/step - loss: 0.2215 - accuracy: 0.6381\n",
      "3432/3432 [==============================] - 2s 661us/step - loss: 0.2231 - accuracy: 0.6432\n",
      "382/382 [==============================] - 0s 403us/step - loss: 0.2170 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 686us/step - loss: 0.2234 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 387us/step - loss: 0.2160 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 2s 710us/step - loss: 0.2227 - accuracy: 0.6431\n",
      "382/382 [==============================] - 0s 405us/step - loss: 0.2197 - accuracy: 0.6643\n",
      "3432/3432 [==============================] - 3s 748us/step - loss: 0.2228 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 409us/step - loss: 0.2147 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 664us/step - loss: 0.2225 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 384us/step - loss: 0.2215 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 653us/step - loss: 0.2222 - accuracy: 0.6471\n",
      "382/382 [==============================] - 0s 395us/step - loss: 0.2255 - accuracy: 0.6320\n",
      "3432/3432 [==============================] - 2s 631us/step - loss: 0.2213 - accuracy: 0.6471\n",
      "382/382 [==============================] - 0s 377us/step - loss: 0.2207 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 627us/step - loss: 0.2225 - accuracy: 0.6460\n",
      "382/382 [==============================] - 0s 384us/step - loss: 0.2203 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 655us/step - loss: 0.2230 - accuracy: 0.6402\n",
      "382/382 [==============================] - 0s 392us/step - loss: 0.2171 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 655us/step - loss: 0.2226 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 397us/step - loss: 0.2217 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 647us/step - loss: 0.2228 - accuracy: 0.6431\n",
      "382/382 [==============================] - 0s 393us/step - loss: 0.2161 - accuracy: 0.6626\n",
      "3432/3432 [==============================] - 2s 625us/step - loss: 0.2228 - accuracy: 0.6429\n",
      "382/382 [==============================] - 0s 390us/step - loss: 0.2190 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 628us/step - loss: 0.2228 - accuracy: 0.6437\n",
      "382/382 [==============================] - 0s 363us/step - loss: 0.2222 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 2s 660us/step - loss: 0.2230 - accuracy: 0.6407\n",
      "382/382 [==============================] - 0s 405us/step - loss: 0.2168 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 656us/step - loss: 0.2223 - accuracy: 0.6421\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 0s 386us/step - loss: 0.2208 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 2s 663us/step - loss: 0.2218 - accuracy: 0.6512\n",
      "382/382 [==============================] - 0s 374us/step - loss: 0.2242 - accuracy: 0.6329\n",
      "3432/3432 [==============================] - 2s 671us/step - loss: 0.2227 - accuracy: 0.6489\n",
      "382/382 [==============================] - 0s 369us/step - loss: 0.2215 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 666us/step - loss: 0.2222 - accuracy: 0.6472\n",
      "382/382 [==============================] - 0s 377us/step - loss: 0.2206 - accuracy: 0.6381\n",
      "3432/3432 [==============================] - 2s 655us/step - loss: 0.2229 - accuracy: 0.6458\n",
      "382/382 [==============================] - 0s 420us/step - loss: 0.2164 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 2s 653us/step - loss: 0.2228 - accuracy: 0.6442\n",
      "382/382 [==============================] - 0s 363us/step - loss: 0.2237 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 665us/step - loss: 0.2230 - accuracy: 0.6420\n",
      "382/382 [==============================] - 0s 377us/step - loss: 0.2192 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 2s 672us/step - loss: 0.2233 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 398us/step - loss: 0.2170 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 658us/step - loss: 0.2223 - accuracy: 0.6473\n",
      "382/382 [==============================] - 0s 360us/step - loss: 0.2213 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 659us/step - loss: 0.2231 - accuracy: 0.6479\n",
      "382/382 [==============================] - 0s 371us/step - loss: 0.2136 - accuracy: 0.6661\n",
      "3432/3432 [==============================] - 2s 671us/step - loss: 0.2226 - accuracy: 0.6437\n",
      "382/382 [==============================] - 0s 376us/step - loss: 0.2188 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 2s 668us/step - loss: 0.2223 - accuracy: 0.6474\n",
      "382/382 [==============================] - 0s 408us/step - loss: 0.2253 - accuracy: 0.6381\n",
      "3432/3432 [==============================] - 2s 639us/step - loss: 0.2219 - accuracy: 0.6504\n",
      "382/382 [==============================] - 0s 401us/step - loss: 0.2229 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 2s 651us/step - loss: 0.2226 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 399us/step - loss: 0.2216 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 2s 659us/step - loss: 0.2232 - accuracy: 0.6429\n",
      "382/382 [==============================] - 0s 394us/step - loss: 0.2173 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 675us/step - loss: 0.2222 - accuracy: 0.6464\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2218 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 667us/step - loss: 0.2233 - accuracy: 0.6431\n",
      "382/382 [==============================] - 0s 408us/step - loss: 0.2155 - accuracy: 0.6687\n",
      "3432/3432 [==============================] - 2s 668us/step - loss: 0.2231 - accuracy: 0.6427\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2179 - accuracy: 0.6407\n",
      "3432/3432 [==============================] - 2s 645us/step - loss: 0.2227 - accuracy: 0.6471\n",
      "382/382 [==============================] - 0s 417us/step - loss: 0.2189 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 670us/step - loss: 0.2232 - accuracy: 0.6406\n",
      "382/382 [==============================] - 0s 377us/step - loss: 0.2168 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 2s 678us/step - loss: 0.2223 - accuracy: 0.6475\n",
      "382/382 [==============================] - 0s 418us/step - loss: 0.2204 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 684us/step - loss: 0.2222 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2237 - accuracy: 0.6407\n",
      "3432/3432 [==============================] - 2s 659us/step - loss: 0.2219 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 418us/step - loss: 0.2357 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 653us/step - loss: 0.2230 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 390us/step - loss: 0.2193 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 664us/step - loss: 0.2232 - accuracy: 0.6437\n",
      "382/382 [==============================] - 0s 404us/step - loss: 0.2181 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 689us/step - loss: 0.2223 - accuracy: 0.6497\n",
      "382/382 [==============================] - 0s 411us/step - loss: 0.2232 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 2s 696us/step - loss: 0.2234 - accuracy: 0.6408\n",
      "382/382 [==============================] - 0s 412us/step - loss: 0.2143 - accuracy: 0.6661\n",
      "3432/3432 [==============================] - 2s 688us/step - loss: 0.2233 - accuracy: 0.6437\n",
      "382/382 [==============================] - 0s 401us/step - loss: 0.2166 - accuracy: 0.6617\n",
      "3432/3432 [==============================] - 2s 650us/step - loss: 0.2223 - accuracy: 0.6423\n",
      "382/382 [==============================] - 0s 399us/step - loss: 0.2218 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 677us/step - loss: 0.2230 - accuracy: 0.6419\n",
      "382/382 [==============================] - 0s 389us/step - loss: 0.2186 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 669us/step - loss: 0.2228 - accuracy: 0.6502\n",
      "382/382 [==============================] - 0s 374us/step - loss: 0.2189 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 2s 684us/step - loss: 0.2221 - accuracy: 0.6438\n",
      "382/382 [==============================] - 0s 396us/step - loss: 0.2246 - accuracy: 0.6381\n",
      "3432/3432 [==============================] - 2s 697us/step - loss: 0.2229 - accuracy: 0.6418\n",
      "382/382 [==============================] - 0s 393us/step - loss: 0.2218 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 653us/step - loss: 0.2224 - accuracy: 0.6490\n",
      "382/382 [==============================] - 0s 381us/step - loss: 0.2194 - accuracy: 0.6407\n",
      "3432/3432 [==============================] - 2s 677us/step - loss: 0.2230 - accuracy: 0.6430\n",
      "382/382 [==============================] - 0s 400us/step - loss: 0.2162 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 678us/step - loss: 0.2222 - accuracy: 0.6476\n",
      "382/382 [==============================] - 0s 390us/step - loss: 0.2225 - accuracy: 0.6320\n",
      "3432/3432 [==============================] - 2s 682us/step - loss: 0.2228 - accuracy: 0.6406\n",
      "382/382 [==============================] - 0s 391us/step - loss: 0.2152 - accuracy: 0.6661\n",
      "3432/3432 [==============================] - 2s 679us/step - loss: 0.2230 - accuracy: 0.6431\n",
      "382/382 [==============================] - 0s 398us/step - loss: 0.2178 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 2s 672us/step - loss: 0.2224 - accuracy: 0.6422\n",
      "382/382 [==============================] - 0s 396us/step - loss: 0.2204 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 681us/step - loss: 0.2228 - accuracy: 0.6419\n",
      "382/382 [==============================] - 0s 425us/step - loss: 0.2165 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 683us/step - loss: 0.2224 - accuracy: 0.6461\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2208 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 688us/step - loss: 0.2220 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 396us/step - loss: 0.2249 - accuracy: 0.6337\n",
      "3432/3432 [==============================] - 2s 663us/step - loss: 0.2222 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 352us/step - loss: 0.2249 - accuracy: 0.6355\n",
      "3432/3432 [==============================] - 2s 663us/step - loss: 0.2222 - accuracy: 0.6461\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2207 - accuracy: 0.6407\n",
      "3432/3432 [==============================] - 2s 684us/step - loss: 0.2227 - accuracy: 0.6461\n",
      "382/382 [==============================] - 0s 382us/step - loss: 0.2169 - accuracy: 0.6600\n",
      "3432/3432 [==============================] - 2s 690us/step - loss: 0.2221 - accuracy: 0.6453\n",
      "382/382 [==============================] - 0s 395us/step - loss: 0.2275 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 2s 660us/step - loss: 0.2231 - accuracy: 0.6430\n",
      "382/382 [==============================] - 0s 376us/step - loss: 0.2170 - accuracy: 0.6687\n",
      "3432/3432 [==============================] - 2s 666us/step - loss: 0.2235 - accuracy: 0.6430\n",
      "382/382 [==============================] - 0s 372us/step - loss: 0.2192 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 658us/step - loss: 0.2223 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 378us/step - loss: 0.2196 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 692us/step - loss: 0.2233 - accuracy: 0.6418\n",
      "382/382 [==============================] - 0s 383us/step - loss: 0.2160 - accuracy: 0.6652\n",
      "3432/3432 [==============================] - 2s 686us/step - loss: 0.2226 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 382us/step - loss: 0.2213 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 701us/step - loss: 0.2218 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 400us/step - loss: 0.2236 - accuracy: 0.6320\n",
      "3432/3432 [==============================] - 2s 692us/step - loss: 0.2221 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 383us/step - loss: 0.2232 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 2s 682us/step - loss: 0.2218 - accuracy: 0.6466\n",
      "382/382 [==============================] - 0s 397us/step - loss: 0.2257 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 681us/step - loss: 0.2224 - accuracy: 0.6483\n",
      "382/382 [==============================] - 0s 397us/step - loss: 0.2180 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 699us/step - loss: 0.2228 - accuracy: 0.6452\n",
      "382/382 [==============================] - 0s 403us/step - loss: 0.2220 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 2s 701us/step - loss: 0.2227 - accuracy: 0.6435\n",
      "382/382 [==============================] - 0s 383us/step - loss: 0.2157 - accuracy: 0.6670\n",
      "3432/3432 [==============================] - 2s 688us/step - loss: 0.2227 - accuracy: 0.6453\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2183 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 2s 668us/step - loss: 0.2228 - accuracy: 0.6412\n",
      "382/382 [==============================] - 0s 405us/step - loss: 0.2209 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 2s 680us/step - loss: 0.2233 - accuracy: 0.6490\n",
      "382/382 [==============================] - 0s 363us/step - loss: 0.2161 - accuracy: 0.6617\n",
      "3432/3432 [==============================] - 2s 681us/step - loss: 0.2224 - accuracy: 0.6484\n",
      "382/382 [==============================] - 0s 416us/step - loss: 0.2203 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 2s 683us/step - loss: 0.2222 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 416us/step - loss: 0.2240 - accuracy: 0.6364\n",
      "3432/3432 [==============================] - 2s 692us/step - loss: 0.2224 - accuracy: 0.6424\n",
      "382/382 [==============================] - 0s 370us/step - loss: 0.2222 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 699us/step - loss: 0.2226 - accuracy: 0.6466\n",
      "382/382 [==============================] - 0s 383us/step - loss: 0.2203 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 691us/step - loss: 0.2230 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 382us/step - loss: 0.2190 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 2s 698us/step - loss: 0.2223 - accuracy: 0.6490\n",
      "382/382 [==============================] - 0s 417us/step - loss: 0.2230 - accuracy: 0.6407\n",
      "3432/3432 [==============================] - 2s 682us/step - loss: 0.2229 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 402us/step - loss: 0.2185 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 696us/step - loss: 0.2229 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 402us/step - loss: 0.2164 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 722us/step - loss: 0.2224 - accuracy: 0.6414\n",
      "382/382 [==============================] - 0s 404us/step - loss: 0.2230 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 672us/step - loss: 0.2230 - accuracy: 0.6422\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2212 - accuracy: 0.6381\n",
      "3432/3432 [==============================] - 2s 676us/step - loss: 0.2223 - accuracy: 0.6428\n",
      "382/382 [==============================] - 0s 385us/step - loss: 0.2208 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 698us/step - loss: 0.2220 - accuracy: 0.6463\n",
      "382/382 [==============================] - 0s 404us/step - loss: 0.2227 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 695us/step - loss: 0.2220 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2223 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 709us/step - loss: 0.2223 - accuracy: 0.6488\n",
      "382/382 [==============================] - 0s 394us/step - loss: 0.2195 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 2s 701us/step - loss: 0.2230 - accuracy: 0.6448\n",
      "382/382 [==============================] - 0s 405us/step - loss: 0.2152 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 712us/step - loss: 0.2225 - accuracy: 0.6433\n",
      "382/382 [==============================] - 0s 388us/step - loss: 0.2213 - accuracy: 0.6600\n",
      "3432/3432 [==============================] - 2s 699us/step - loss: 0.2230 - accuracy: 0.6420\n",
      "382/382 [==============================] - 0s 366us/step - loss: 0.2164 - accuracy: 0.6600\n",
      "3432/3432 [==============================] - 2s 703us/step - loss: 0.2231 - accuracy: 0.6421\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2165 - accuracy: 0.6617\n",
      "3432/3432 [==============================] - 2s 702us/step - loss: 0.2223 - accuracy: 0.6443\n",
      "382/382 [==============================] - 0s 385us/step - loss: 0.2227 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 2s 722us/step - loss: 0.2225 - accuracy: 0.6478\n",
      "382/382 [==============================] - 0s 434us/step - loss: 0.2205 - accuracy: 0.6355\n",
      "3432/3432 [==============================] - 2s 688us/step - loss: 0.2222 - accuracy: 0.6468\n",
      "382/382 [==============================] - 0s 401us/step - loss: 0.2273 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 708us/step - loss: 0.2220 - accuracy: 0.6472\n",
      "382/382 [==============================] - 0s 434us/step - loss: 0.2271 - accuracy: 0.6337\n",
      "3432/3432 [==============================] - 2s 692us/step - loss: 0.2221 - accuracy: 0.6412\n",
      "382/382 [==============================] - 0s 387us/step - loss: 0.2245 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 705us/step - loss: 0.2220 - accuracy: 0.6442\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2211 - accuracy: 0.6390\n",
      "3432/3432 [==============================] - 2s 715us/step - loss: 0.2234 - accuracy: 0.6432\n",
      "382/382 [==============================] - 0s 413us/step - loss: 0.2167 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 676us/step - loss: 0.2221 - accuracy: 0.6443\n",
      "382/382 [==============================] - 0s 402us/step - loss: 0.2229 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 703us/step - loss: 0.2232 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 390us/step - loss: 0.2160 - accuracy: 0.6678\n",
      "3432/3432 [==============================] - 2s 707us/step - loss: 0.2226 - accuracy: 0.6448\n",
      "382/382 [==============================] - 0s 433us/step - loss: 0.2169 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 2s 703us/step - loss: 0.2225 - accuracy: 0.6477\n",
      "382/382 [==============================] - 0s 438us/step - loss: 0.2206 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 712us/step - loss: 0.2230 - accuracy: 0.6459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 0s 388us/step - loss: 0.2145 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 3s 736us/step - loss: 0.2224 - accuracy: 0.6464\n",
      "382/382 [==============================] - 0s 397us/step - loss: 0.2223 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 713us/step - loss: 0.2225 - accuracy: 0.6471\n",
      "382/382 [==============================] - 0s 384us/step - loss: 0.2242 - accuracy: 0.6241\n",
      "3432/3432 [==============================] - 2s 721us/step - loss: 0.2222 - accuracy: 0.6461\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2229 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 721us/step - loss: 0.2230 - accuracy: 0.6437\n",
      "382/382 [==============================] - 0s 366us/step - loss: 0.2202 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 719us/step - loss: 0.2235 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 400us/step - loss: 0.2174 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 716us/step - loss: 0.2220 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 405us/step - loss: 0.2247 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 2s 683us/step - loss: 0.2233 - accuracy: 0.6412\n",
      "382/382 [==============================] - 0s 391us/step - loss: 0.2148 - accuracy: 0.6652\n",
      "3432/3432 [==============================] - 2s 690us/step - loss: 0.2231 - accuracy: 0.6503\n",
      "382/382 [==============================] - 0s 399us/step - loss: 0.2166 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 717us/step - loss: 0.2225 - accuracy: 0.6468\n",
      "382/382 [==============================] - 0s 376us/step - loss: 0.2187 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 2s 718us/step - loss: 0.2230 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 428us/step - loss: 0.2139 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 3s 732us/step - loss: 0.2224 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 420us/step - loss: 0.2205 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 2s 725us/step - loss: 0.2218 - accuracy: 0.6458\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2259 - accuracy: 0.6259\n",
      "3432/3432 [==============================] - 2s 724us/step - loss: 0.2225 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 402us/step - loss: 0.2231 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 690us/step - loss: 0.2222 - accuracy: 0.64290s - loss: 0.2221 - accura\n",
      "382/382 [==============================] - 0s 408us/step - loss: 0.2221 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 717us/step - loss: 0.2228 - accuracy: 0.6482\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2227 - accuracy: 0.6626\n",
      "3432/3432 [==============================] - 2s 724us/step - loss: 0.2223 - accuracy: 0.6429\n",
      "382/382 [==============================] - 0s 418us/step - loss: 0.2206 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 718us/step - loss: 0.2232 - accuracy: 0.6472\n",
      "382/382 [==============================] - 0s 406us/step - loss: 0.2159 - accuracy: 0.6643\n",
      "3432/3432 [==============================] - 3s 733us/step - loss: 0.2223 - accuracy: 0.6427\n",
      "382/382 [==============================] - 0s 404us/step - loss: 0.2148 - accuracy: 0.6617\n",
      "3432/3432 [==============================] - 3s 731us/step - loss: 0.2227 - accuracy: 0.6460\n",
      "382/382 [==============================] - 0s 401us/step - loss: 0.2193 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 2s 686us/step - loss: 0.2229 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 404us/step - loss: 0.2189 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 2s 723us/step - loss: 0.2225 - accuracy: 0.6428\n",
      "382/382 [==============================] - 0s 400us/step - loss: 0.2293 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 725us/step - loss: 0.2218 - accuracy: 0.6474\n",
      "382/382 [==============================] - 0s 382us/step - loss: 0.2260 - accuracy: 0.6267\n",
      "3432/3432 [==============================] - 2s 699us/step - loss: 0.2229 - accuracy: 0.6432\n",
      "382/382 [==============================] - 0s 410us/step - loss: 0.2217 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 686us/step - loss: 0.2224 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2242 - accuracy: 0.6364\n",
      "3432/3432 [==============================] - 2s 679us/step - loss: 0.2228 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 409us/step - loss: 0.2160 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 709us/step - loss: 0.2222 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2230 - accuracy: 0.6390\n",
      "3432/3432 [==============================] - 2s 713us/step - loss: 0.2232 - accuracy: 0.6428\n",
      "382/382 [==============================] - 0s 390us/step - loss: 0.2163 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 717us/step - loss: 0.2231 - accuracy: 0.6439\n",
      "382/382 [==============================] - 0s 400us/step - loss: 0.2209 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 706us/step - loss: 0.2225 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2201 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 725us/step - loss: 0.2234 - accuracy: 0.6393\n",
      "382/382 [==============================] - 0s 404us/step - loss: 0.2181 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 2s 673us/step - loss: 0.2227 - accuracy: 0.6451\n",
      "382/382 [==============================] - 0s 395us/step - loss: 0.2221 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 717us/step - loss: 0.2223 - accuracy: 0.6480\n",
      "382/382 [==============================] - 0s 401us/step - loss: 0.2263 - accuracy: 0.6372\n",
      "3432/3432 [==============================] - 2s 711us/step - loss: 0.2222 - accuracy: 0.6442\n",
      "382/382 [==============================] - 0s 395us/step - loss: 0.2219 - accuracy: 0.6425\n",
      "3432/3432 [==============================] - 2s 715us/step - loss: 0.2223 - accuracy: 0.6493\n",
      "382/382 [==============================] - 0s 396us/step - loss: 0.2272 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 3s 736us/step - loss: 0.2227 - accuracy: 0.6454\n",
      "382/382 [==============================] - 0s 378us/step - loss: 0.2162 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 3s 734us/step - loss: 0.2226 - accuracy: 0.6493\n",
      "382/382 [==============================] - 0s 409us/step - loss: 0.2224 - accuracy: 0.6390\n",
      "3432/3432 [==============================] - 2s 703us/step - loss: 0.2234 - accuracy: 0.6441\n",
      "382/382 [==============================] - 0s 373us/step - loss: 0.2146 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 2s 725us/step - loss: 0.2233 - accuracy: 0.6429\n",
      "382/382 [==============================] - 0s 395us/step - loss: 0.2190 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 718us/step - loss: 0.2222 - accuracy: 0.6393\n",
      "382/382 [==============================] - 0s 408us/step - loss: 0.2213 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 718us/step - loss: 0.2235 - accuracy: 0.6385\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2220 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 726us/step - loss: 0.2218 - accuracy: 0.6453\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2190 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 693us/step - loss: 0.2222 - accuracy: 0.6476\n",
      "382/382 [==============================] - 0s 391us/step - loss: 0.2261 - accuracy: 0.6399\n",
      "3432/3432 [==============================] - 2s 727us/step - loss: 0.2224 - accuracy: 0.6472\n",
      "382/382 [==============================] - 0s 389us/step - loss: 0.2272 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 3s 735us/step - loss: 0.2229 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 413us/step - loss: 0.2248 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 3s 729us/step - loss: 0.2226 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 402us/step - loss: 0.2169 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 3s 739us/step - loss: 0.2229 - accuracy: 0.6443\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.2041 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0157s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 417us/step - loss: 0.2222 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 2s 685us/step - loss: 0.2229 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 402us/step - loss: 0.2173 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 704us/step - loss: 0.2230 - accuracy: 0.6465\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2218 - accuracy: 0.6670\n",
      "3432/3432 [==============================] - 3s 730us/step - loss: 0.2222 - accuracy: 0.6443\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.2469 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0156s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 416us/step - loss: 0.2201 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 728us/step - loss: 0.2228 - accuracy: 0.6459\n",
      "382/382 [==============================] - 0s 426us/step - loss: 0.2161 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 3s 731us/step - loss: 0.2225 - accuracy: 0.6437\n",
      "382/382 [==============================] - 0s 385us/step - loss: 0.2225 - accuracy: 0.6600\n",
      "3432/3432 [==============================] - 3s 737us/step - loss: 0.2225 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 420us/step - loss: 0.2231 - accuracy: 0.6250\n",
      "3432/3432 [==============================] - 3s 737us/step - loss: 0.2226 - accuracy: 0.6421\n",
      "382/382 [==============================] - 0s 398us/step - loss: 0.2202 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 695us/step - loss: 0.2223 - accuracy: 0.6479\n",
      "382/382 [==============================] - 0s 417us/step - loss: 0.2263 - accuracy: 0.6372\n",
      "3432/3432 [==============================] - 2s 687us/step - loss: 0.2227 - accuracy: 0.6418\n",
      "382/382 [==============================] - 0s 399us/step - loss: 0.2185 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 3s 744us/step - loss: 0.2226 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 455us/step - loss: 0.2216 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 2s 726us/step - loss: 0.2232 - accuracy: 0.6406\n",
      "382/382 [==============================] - 0s 399us/step - loss: 0.2173 - accuracy: 0.6731\n",
      "3432/3432 [==============================] - 3s 742us/step - loss: 0.2228 - accuracy: 0.6421\n",
      "382/382 [==============================] - 0s 404us/step - loss: 0.2181 - accuracy: 0.6626\n",
      "3432/3432 [==============================] - 3s 753us/step - loss: 0.2225 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 376us/step - loss: 0.2202 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 722us/step - loss: 0.2226 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 399us/step - loss: 0.2176 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 720us/step - loss: 0.2226 - accuracy: 0.6439\n",
      "382/382 [==============================] - 0s 382us/step - loss: 0.2207 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 3s 734us/step - loss: 0.2222 - accuracy: 0.6438\n",
      "382/382 [==============================] - 0s 393us/step - loss: 0.2248 - accuracy: 0.6372\n",
      "3432/3432 [==============================] - 3s 730us/step - loss: 0.2220 - accuracy: 0.6454\n",
      "382/382 [==============================] - 0s 403us/step - loss: 0.2218 - accuracy: 0.6425\n",
      "3432/3432 [==============================] - 3s 735us/step - loss: 0.2222 - accuracy: 0.6469\n",
      "382/382 [==============================] - 0s 413us/step - loss: 0.2224 - accuracy: 0.6381\n",
      "3432/3432 [==============================] - 3s 734us/step - loss: 0.2232 - accuracy: 0.6438\n",
      "382/382 [==============================] - 0s 399us/step - loss: 0.2164 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 684us/step - loss: 0.2226 - accuracy: 0.6449\n",
      "382/382 [==============================] - 0s 418us/step - loss: 0.2203 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 2s 712us/step - loss: 0.2233 - accuracy: 0.6437\n",
      "382/382 [==============================] - 0s 392us/step - loss: 0.2160 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 3s 735us/step - loss: 0.2230 - accuracy: 0.6424\n",
      "382/382 [==============================] - 0s 412us/step - loss: 0.2211 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 722us/step - loss: 0.2229 - accuracy: 0.6427\n",
      "382/382 [==============================] - 0s 417us/step - loss: 0.2248 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 3s 740us/step - loss: 0.2229 - accuracy: 0.6420\n",
      "382/382 [==============================] - 0s 424us/step - loss: 0.2156 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 3s 751us/step - loss: 0.2225 - accuracy: 0.6405\n",
      "382/382 [==============================] - 0s 396us/step - loss: 0.2226 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 3s 760us/step - loss: 0.2220 - accuracy: 0.6464\n",
      "382/382 [==============================] - 0s 406us/step - loss: 0.2223 - accuracy: 0.6364\n",
      "3432/3432 [==============================] - 2s 710us/step - loss: 0.2221 - accuracy: 0.6423\n",
      "382/382 [==============================] - 0s 395us/step - loss: 0.2227 - accuracy: 0.6390\n",
      "3432/3432 [==============================] - 3s 742us/step - loss: 0.2226 - accuracy: 0.6449\n",
      "382/382 [==============================] - 0s 438us/step - loss: 0.2202 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 3s 744us/step - loss: 0.2226 - accuracy: 0.6494\n",
      "382/382 [==============================] - 0s 396us/step - loss: 0.2158 - accuracy: 0.6530\n",
      "   1/3432 [..............................] - ETA: 0s - loss: 0.2502 - accuracy: 0.0000e+00WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0156s). Check your callbacks.\n",
      "3432/3432 [==============================] - 3s 740us/step - loss: 0.2229 - accuracy: 0.6451\n",
      "382/382 [==============================] - 0s 401us/step - loss: 0.2242 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 3s 749us/step - loss: 0.2226 - accuracy: 0.6432\n",
      "382/382 [==============================] - 0s 404us/step - loss: 0.2163 - accuracy: 0.6670\n",
      "3432/3432 [==============================] - 2s 704us/step - loss: 0.2232 - accuracy: 0.6420\n",
      "382/382 [==============================] - 0s 418us/step - loss: 0.2138 - accuracy: 0.6687\n",
      "3432/3432 [==============================] - 2s 710us/step - loss: 0.2225 - accuracy: 0.6462\n",
      "382/382 [==============================] - 0s 392us/step - loss: 0.2199 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 3s 744us/step - loss: 0.2232 - accuracy: 0.6454\n",
      "382/382 [==============================] - 0s 436us/step - loss: 0.2160 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 3s 740us/step - loss: 0.2225 - accuracy: 0.6449\n",
      "382/382 [==============================] - 0s 387us/step - loss: 0.2193 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 3s 740us/step - loss: 0.2220 - accuracy: 0.6477\n",
      "382/382 [==============================] - 0s 395us/step - loss: 0.2249 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 720us/step - loss: 0.2222 - accuracy: 0.6409\n",
      "382/382 [==============================] - 0s 408us/step - loss: 0.2221 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 3s 735us/step - loss: 0.2225 - accuracy: 0.6445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 0s 436us/step - loss: 0.2213 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 704us/step - loss: 0.2228 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2166 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 3s 756us/step - loss: 0.2225 - accuracy: 0.6491\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2203 - accuracy: 0.6372\n",
      "3432/3432 [==============================] - 3s 749us/step - loss: 0.2232 - accuracy: 0.6441\n",
      "382/382 [==============================] - 0s 406us/step - loss: 0.2188 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 3s 753us/step - loss: 0.2228 - accuracy: 0.6421\n",
      "382/382 [==============================] - 0s 394us/step - loss: 0.2162 - accuracy: 0.6626\n",
      "3432/3432 [==============================] - 3s 759us/step - loss: 0.2225 - accuracy: 0.6449\n",
      "382/382 [==============================] - 0s 402us/step - loss: 0.2192 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 3s 757us/step - loss: 0.2230 - accuracy: 0.6414\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2162 - accuracy: 0.6407\n",
      "3432/3432 [==============================] - 2s 701us/step - loss: 0.2223 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 393us/step - loss: 0.2228 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 3s 761us/step - loss: 0.2221 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2229 - accuracy: 0.6381\n",
      "3432/3432 [==============================] - 3s 752us/step - loss: 0.2227 - accuracy: 0.6409\n",
      "382/382 [==============================] - 0s 478us/step - loss: 0.2241 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 3s 767us/step - loss: 0.2222 - accuracy: 0.6473\n",
      "382/382 [==============================] - 0s 406us/step - loss: 0.2233 - accuracy: 0.6346\n",
      "3432/3432 [==============================] - 3s 757us/step - loss: 0.2230 - accuracy: 0.6478\n",
      "382/382 [==============================] - 0s 404us/step - loss: 0.2173 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 3s 765us/step - loss: 0.2226 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 417us/step - loss: 0.2210 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 3s 732us/step - loss: 0.2228 - accuracy: 0.6458\n",
      "382/382 [==============================] - 0s 403us/step - loss: 0.2166 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 3s 763us/step - loss: 0.2233 - accuracy: 0.6433\n",
      "382/382 [==============================] - 0s 372us/step - loss: 0.2163 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 3s 743us/step - loss: 0.2222 - accuracy: 0.6419\n",
      "382/382 [==============================] - 0s 407us/step - loss: 0.2200 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 3s 757us/step - loss: 0.2230 - accuracy: 0.6442\n",
      "382/382 [==============================] - 0s 396us/step - loss: 0.2174 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 3s 758us/step - loss: 0.2222 - accuracy: 0.6467\n",
      "382/382 [==============================] - 0s 404us/step - loss: 0.2201 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 721us/step - loss: 0.2218 - accuracy: 0.6462\n",
      "382/382 [==============================] - 0s 393us/step - loss: 0.2231 - accuracy: 0.6276\n",
      "   1/3432 [..............................] - ETA: 0s - loss: 0.2500 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0156s). Check your callbacks.\n",
      "3432/3432 [==============================] - 2s 709us/step - loss: 0.2225 - accuracy: 0.6430\n",
      "382/382 [==============================] - 0s 416us/step - loss: 0.2235 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 3s 760us/step - loss: 0.2220 - accuracy: 0.6483\n",
      "382/382 [==============================] - 0s 400us/step - loss: 0.2218 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 3s 755us/step - loss: 0.2232 - accuracy: 0.6438\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2171 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 3s 751us/step - loss: 0.2228 - accuracy: 0.6465\n",
      "382/382 [==============================] - 0s 411us/step - loss: 0.2196 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 3s 764us/step - loss: 0.2229 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 395us/step - loss: 0.2149 - accuracy: 0.6670\n",
      "3432/3432 [==============================] - 3s 734us/step - loss: 0.2227 - accuracy: 0.6453\n",
      "382/382 [==============================] - 0s 421us/step - loss: 0.2151 - accuracy: 0.6661\n",
      "3432/3432 [==============================] - 3s 747us/step - loss: 0.2222 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 394us/step - loss: 0.2197 - accuracy: 0.6626\n",
      "3432/3432 [==============================] - 2s 708us/step - loss: 0.2229 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 442us/step - loss: 0.2158 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 3s 764us/step - loss: 0.2224 - accuracy: 0.6459\n",
      "382/382 [==============================] - 0s 401us/step - loss: 0.2220 - accuracy: 0.6626\n",
      "3432/3432 [==============================] - 3s 761us/step - loss: 0.2222 - accuracy: 0.6476\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2236 - accuracy: 0.6285\n",
      "3432/3432 [==============================] - 3s 765us/step - loss: 0.2223 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 413us/step - loss: 0.2226 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 3s 766us/step - loss: 0.2219 - accuracy: 0.6467\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2256 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 3s 790us/step - loss: 0.2233 - accuracy: 0.6419\n",
      "382/382 [==============================] - 0s 455us/step - loss: 0.2189 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 2s 724us/step - loss: 0.2226 - accuracy: 0.6458\n",
      "382/382 [==============================] - 0s 441us/step - loss: 0.2203 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 3s 775us/step - loss: 0.2234 - accuracy: 0.6430\n",
      "382/382 [==============================] - 0s 448us/step - loss: 0.2160 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 3s 756us/step - loss: 0.2233 - accuracy: 0.6422\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2169 - accuracy: 0.6643\n",
      "3432/3432 [==============================] - 3s 762us/step - loss: 0.2226 - accuracy: 0.6428\n",
      "382/382 [==============================] - 0s 404us/step - loss: 0.2199 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 3s 766us/step - loss: 0.2232 - accuracy: 0.6474\n",
      "382/382 [==============================] - 0s 442us/step - loss: 0.2183 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 3s 784us/step - loss: 0.2228 - accuracy: 0.6414\n",
      "382/382 [==============================] - 0s 469us/step - loss: 0.2199 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 716us/step - loss: 0.2219 - accuracy: 0.6496\n",
      "382/382 [==============================] - 0s 405us/step - loss: 0.2223 - accuracy: 0.6399\n",
      "3432/3432 [==============================] - 3s 834us/step - loss: 0.2230 - accuracy: 0.6460\n",
      "382/382 [==============================] - 0s 400us/step - loss: 0.2205 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 3s 767us/step - loss: 0.2222 - accuracy: 0.6443\n",
      "382/382 [==============================] - 0s 399us/step - loss: 0.2228 - accuracy: 0.6399\n",
      "3432/3432 [==============================] - 3s 764us/step - loss: 0.2232 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 399us/step - loss: 0.2181 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 3s 761us/step - loss: 0.2227 - accuracy: 0.6457\n",
      "382/382 [==============================] - 0s 413us/step - loss: 0.2205 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 3s 737us/step - loss: 0.2233 - accuracy: 0.6424\n",
      "382/382 [==============================] - 0s 386us/step - loss: 0.2187 - accuracy: 0.6617\n",
      "3432/3432 [==============================] - 2s 726us/step - loss: 0.2227 - accuracy: 0.6432\n",
      "382/382 [==============================] - 0s 425us/step - loss: 0.2159 - accuracy: 0.6670\n",
      "3432/3432 [==============================] - 2s 722us/step - loss: 0.2221 - accuracy: 0.6429\n",
      "382/382 [==============================] - 0s 401us/step - loss: 0.2203 - accuracy: 0.6626\n",
      "3432/3432 [==============================] - 3s 769us/step - loss: 0.2237 - accuracy: 0.6437\n",
      "382/382 [==============================] - 0s 427us/step - loss: 0.2138 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 3s 769us/step - loss: 0.2223 - accuracy: 0.6486\n",
      "382/382 [==============================] - 0s 409us/step - loss: 0.2217 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 3s 760us/step - loss: 0.2217 - accuracy: 0.6475\n",
      "382/382 [==============================] - 0s 383us/step - loss: 0.2225 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 3s 786us/step - loss: 0.2220 - accuracy: 0.6468\n",
      "382/382 [==============================] - 0s 395us/step - loss: 0.2224 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 3s 766us/step - loss: 0.2228 - accuracy: 0.6474\n",
      "382/382 [==============================] - 0s 430us/step - loss: 0.2252 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 3s 782us/step - loss: 0.2228 - accuracy: 0.6430\n",
      "382/382 [==============================] - 0s 380us/step - loss: 0.2165 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 3s 763us/step - loss: 0.2226 - accuracy: 0.6460\n",
      "382/382 [==============================] - 0s 412us/step - loss: 0.2203 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 3s 774us/step - loss: 0.2233 - accuracy: 0.6455\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2187 - accuracy: 0.6626\n",
      "3432/3432 [==============================] - 3s 764us/step - loss: 0.2232 - accuracy: 0.6395\n",
      "382/382 [==============================] - 0s 418us/step - loss: 0.2159 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 3s 781us/step - loss: 0.2226 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 373us/step - loss: 0.2185 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 3s 752us/step - loss: 0.2232 - accuracy: 0.6426\n",
      "382/382 [==============================] - 0s 416us/step - loss: 0.2151 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 3s 742us/step - loss: 0.2222 - accuracy: 0.6462\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2212 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 3s 735us/step - loss: 0.2220 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 421us/step - loss: 0.2257 - accuracy: 0.6337\n",
      "3432/3432 [==============================] - 3s 772us/step - loss: 0.2227 - accuracy: 0.6422\n",
      "382/382 [==============================] - 0s 413us/step - loss: 0.2236 - accuracy: 0.6346\n",
      "3432/3432 [==============================] - 3s 778us/step - loss: 0.2222 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 418us/step - loss: 0.2227 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 3s 783us/step - loss: 0.2236 - accuracy: 0.6454\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2158 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 3s 787us/step - loss: 0.2228 - accuracy: 0.6428\n",
      "382/382 [==============================] - 0s 432us/step - loss: 0.2202 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 3s 810us/step - loss: 0.2225 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 401us/step - loss: 0.2141 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 3s 729us/step - loss: 0.2227 - accuracy: 0.6469\n",
      "382/382 [==============================] - 0s 416us/step - loss: 0.2174 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 3s 780us/step - loss: 0.2230 - accuracy: 0.6442\n",
      "382/382 [==============================] - 0s 441us/step - loss: 0.2238 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 3s 787us/step - loss: 0.2228 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 409us/step - loss: 0.2155 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 3s 782us/step - loss: 0.2219 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 438us/step - loss: 0.2235 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 3s 791us/step - loss: 0.2223 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 443us/step - loss: 0.2248 - accuracy: 0.6189\n",
      "3432/3432 [==============================] - 3s 766us/step - loss: 0.2223 - accuracy: 0.6482\n",
      "382/382 [==============================] - 0s 445us/step - loss: 0.2217 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 3s 751us/step - loss: 0.2228 - accuracy: 0.6474\n",
      "382/382 [==============================] - 0s 398us/step - loss: 0.2219 - accuracy: 0.6390\n",
      "3432/3432 [==============================] - 3s 743us/step - loss: 0.2225 - accuracy: 0.6433\n",
      "382/382 [==============================] - 0s 404us/step - loss: 0.2171 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 3s 798us/step - loss: 0.2217 - accuracy: 0.6427\n",
      "382/382 [==============================] - 0s 456us/step - loss: 0.2228 - accuracy: 0.6425\n",
      "3432/3432 [==============================] - 3s 790us/step - loss: 0.2225 - accuracy: 0.6455\n",
      "382/382 [==============================] - 0s 454us/step - loss: 0.2140 - accuracy: 0.6678\n",
      "3432/3432 [==============================] - 3s 791us/step - loss: 0.2230 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 439us/step - loss: 0.2173 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 3s 781us/step - loss: 0.2225 - accuracy: 0.6435\n",
      "382/382 [==============================] - 0s 413us/step - loss: 0.2205 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 3s 820us/step - loss: 0.2227 - accuracy: 0.6463\n",
      "382/382 [==============================] - 0s 413us/step - loss: 0.2164 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 3s 752us/step - loss: 0.2221 - accuracy: 0.6466\n",
      "382/382 [==============================] - 0s 428us/step - loss: 0.2208 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 3s 754us/step - loss: 0.2223 - accuracy: 0.6469\n",
      "382/382 [==============================] - 0s 417us/step - loss: 0.2251 - accuracy: 0.6390\n",
      "3432/3432 [==============================] - 3s 781us/step - loss: 0.2222 - accuracy: 0.6448\n",
      "382/382 [==============================] - 0s 429us/step - loss: 0.2204 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 3s 781us/step - loss: 0.2225 - accuracy: 0.6443\n",
      "382/382 [==============================] - 0s 420us/step - loss: 0.2220 - accuracy: 0.6381\n",
      "3432/3432 [==============================] - 3s 786us/step - loss: 0.2232 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 388us/step - loss: 0.2164 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 3s 793us/step - loss: 0.2226 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 481us/step - loss: 0.2270 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 3s 797us/step - loss: 0.2227 - accuracy: 0.6433\n",
      "382/382 [==============================] - 0s 446us/step - loss: 0.2175 - accuracy: 0.6678\n",
      "3432/3432 [==============================] - 3s 746us/step - loss: 0.2233 - accuracy: 0.6412\n",
      "382/382 [==============================] - 0s 399us/step - loss: 0.2187 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 3s 793us/step - loss: 0.2225 - accuracy: 0.6441\n",
      "382/382 [==============================] - 0s 441us/step - loss: 0.2237 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 3s 782us/step - loss: 0.2229 - accuracy: 0.6449\n",
      "382/382 [==============================] - 0s 402us/step - loss: 0.2162 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 3s 780us/step - loss: 0.2223 - accuracy: 0.6381\n",
      "382/382 [==============================] - 0s 437us/step - loss: 0.2259 - accuracy: 0.6486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3432/3432 [==============================] - 3s 799us/step - loss: 0.2228 - accuracy: 0.6431\n",
      "382/382 [==============================] - 0s 395us/step - loss: 0.2258 - accuracy: 0.6407\n",
      "3432/3432 [==============================] - 3s 772us/step - loss: 0.2224 - accuracy: 0.6443\n",
      "382/382 [==============================] - 0s 385us/step - loss: 0.2248 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 3s 749us/step - loss: 0.2225 - accuracy: 0.6445\n",
      "382/382 [==============================] - 0s 404us/step - loss: 0.2256 - accuracy: 0.6399\n",
      "3432/3432 [==============================] - 3s 736us/step - loss: 0.2230 - accuracy: 0.6427\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2164 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 3s 797us/step - loss: 0.2223 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 444us/step - loss: 0.2221 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 3s 801us/step - loss: 0.2232 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 425us/step - loss: 0.2168 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 3s 791us/step - loss: 0.2233 - accuracy: 0.6403\n",
      "382/382 [==============================] - 0s 469us/step - loss: 0.2179 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 3s 812us/step - loss: 0.2230 - accuracy: 0.6400\n",
      "382/382 [==============================] - 0s 444us/step - loss: 0.2224 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 3s 805us/step - loss: 0.2230 - accuracy: 0.6431\n",
      "382/382 [==============================] - 0s 468us/step - loss: 0.2169 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 3s 777us/step - loss: 0.2224 - accuracy: 0.6458\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.1624 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0157s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 434us/step - loss: 0.2198 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 3s 753us/step - loss: 0.2223 - accuracy: 0.6448\n",
      "382/382 [==============================] - 0s 409us/step - loss: 0.2256 - accuracy: 0.6329\n",
      "3432/3432 [==============================] - 3s 802us/step - loss: 0.2219 - accuracy: 0.6477\n",
      "382/382 [==============================] - 0s 443us/step - loss: 0.2246 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 3s 790us/step - loss: 0.2230 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 438us/step - loss: 0.2212 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 3s 795us/step - loss: 0.2226 - accuracy: 0.6442\n",
      "382/382 [==============================] - 0s 386us/step - loss: 0.2211 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 3s 814us/step - loss: 0.2229 - accuracy: 0.6458\n",
      "382/382 [==============================] - 0s 464us/step - loss: 0.2232 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 3s 822us/step - loss: 0.2232 - accuracy: 0.6459\n",
      "382/382 [==============================] - 0s 451us/step - loss: 0.2178 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 3s 748us/step - loss: 0.2237 - accuracy: 0.6424\n",
      "382/382 [==============================] - 0s 418us/step - loss: 0.2143 - accuracy: 0.6687\n",
      "3432/3432 [==============================] - ETA: 0s - loss: 0.2221 - accuracy: 0.64 - 3s 763us/step - loss: 0.2218 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 397us/step - loss: 0.2237 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 3s 794us/step - loss: 0.2234 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 460us/step - loss: 0.2171 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 3s 795us/step - loss: 0.2222 - accuracy: 0.6468\n",
      "382/382 [==============================] - 0s 388us/step - loss: 0.2205 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 3s 789us/step - loss: 0.2215 - accuracy: 0.6452\n",
      "382/382 [==============================] - 0s 442us/step - loss: 0.2296 - accuracy: 0.6241\n",
      "3432/3432 [==============================] - 3s 798us/step - loss: 0.2217 - accuracy: 0.6413\n",
      "382/382 [==============================] - 0s 459us/step - loss: 0.2214 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 3s 811us/step - loss: 0.2216 - accuracy: 0.6469\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2203 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 3s 763us/step - loss: 0.2227 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 404us/step - loss: 0.2151 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 3s 753us/step - loss: 0.2224 - accuracy: 0.6460\n",
      "382/382 [==============================] - 0s 390us/step - loss: 0.2263 - accuracy: 0.6294\n",
      "3432/3432 [==============================] - 3s 804us/step - loss: 0.2230 - accuracy: 0.6429\n",
      "382/382 [==============================] - 0s 438us/step - loss: 0.2147 - accuracy: 0.6617\n",
      "3432/3432 [==============================] - 3s 802us/step - loss: 0.2234 - accuracy: 0.6417\n",
      "382/382 [==============================] - 0s 441us/step - loss: 0.2162 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 3s 819us/step - loss: 0.2228 - accuracy: 0.6438\n",
      "382/382 [==============================] - 0s 454us/step - loss: 0.2237 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 3s 813us/step - loss: 0.2231 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 399us/step - loss: 0.2143 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 3s 823us/step - loss: 0.2227 - accuracy: 0.6427\n",
      "382/382 [==============================] - 0s 442us/step - loss: 0.2225 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 3s 771us/step - loss: 0.2218 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 428us/step - loss: 0.2271 - accuracy: 0.6337\n",
      "3432/3432 [==============================] - 3s 773us/step - loss: 0.2221 - accuracy: 0.6465\n",
      "382/382 [==============================] - 0s 417us/step - loss: 0.2229 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 3s 809us/step - loss: 0.2226 - accuracy: 0.6465\n",
      "382/382 [==============================] - 0s 408us/step - loss: 0.2202 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 3s 812us/step - loss: 0.2234 - accuracy: 0.6458\n",
      "382/382 [==============================] - 0s 384us/step - loss: 0.2153 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 3s 807us/step - loss: 0.2228 - accuracy: 0.6407\n",
      "382/382 [==============================] - 0s 446us/step - loss: 0.2220 - accuracy: 0.6399\n",
      "3432/3432 [==============================] - 3s 805us/step - loss: 0.2233 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 397us/step - loss: 0.2195 - accuracy: 0.6626\n",
      "3432/3432 [==============================] - 3s 850us/step - loss: 0.2232 - accuracy: 0.6453\n",
      "382/382 [==============================] - 0s 435us/step - loss: 0.2199 - accuracy: 0.6643\n",
      "3432/3432 [==============================] - 3s 787us/step - loss: 0.2222 - accuracy: 0.6453\n",
      "382/382 [==============================] - 0s 406us/step - loss: 0.2221 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 3s 774us/step - loss: 0.2236 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 368us/step - loss: 0.2148 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 3s 811us/step - loss: 0.2225 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 451us/step - loss: 0.2235 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 3s 801us/step - loss: 0.2221 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 448us/step - loss: 0.2275 - accuracy: 0.6302\n",
      "3432/3432 [==============================] - 3s 798us/step - loss: 0.2225 - accuracy: 0.6442\n",
      "382/382 [==============================] - 0s 444us/step - loss: 0.2264 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 3s 821us/step - loss: 0.2222 - accuracy: 0.6461\n",
      "382/382 [==============================] - 0s 416us/step - loss: 0.2202 - accuracy: 0.6390\n",
      "3432/3432 [==============================] - 3s 831us/step - loss: 0.2227 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 467us/step - loss: 0.2195 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 3s 766us/step - loss: 0.2225 - accuracy: 0.6433\n",
      "382/382 [==============================] - 0s 402us/step - loss: 0.2195 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 3s 770us/step - loss: 0.2238 - accuracy: 0.6411\n",
      "382/382 [==============================] - 0s 378us/step - loss: 0.2150 - accuracy: 0.6713\n",
      "3432/3432 [==============================] - 3s 823us/step - loss: 0.2226 - accuracy: 0.6461\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2169 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 3s 809us/step - loss: 0.2219 - accuracy: 0.6441\n",
      "382/382 [==============================] - 0s 413us/step - loss: 0.2267 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 3s 809us/step - loss: 0.2221 - accuracy: 0.6487\n",
      "382/382 [==============================] - 0s 468us/step - loss: 0.2172 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 3s 820us/step - loss: 0.2224 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 440us/step - loss: 0.2218 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 3s 829us/step - loss: 0.2219 - accuracy: 0.6453\n",
      "382/382 [==============================] - 0s 458us/step - loss: 0.2223 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 3s 770us/step - loss: 0.2223 - accuracy: 0.6462\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2276 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 3s 775us/step - loss: 0.2219 - accuracy: 0.6408\n",
      "382/382 [==============================] - 0s 397us/step - loss: 0.2196 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 3s 818us/step - loss: 0.2232 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 408us/step - loss: 0.2170 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 3s 821us/step - loss: 0.2221 - accuracy: 0.6422\n",
      "382/382 [==============================] - 0s 432us/step - loss: 0.2228 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 3s 813us/step - loss: 0.2227 - accuracy: 0.6424\n",
      "382/382 [==============================] - 0s 401us/step - loss: 0.2150 - accuracy: 0.6670\n",
      "3432/3432 [==============================] - 3s 835us/step - loss: 0.2233 - accuracy: 0.6463\n",
      "382/382 [==============================] - 0s 464us/step - loss: 0.2155 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 3s 850us/step - loss: 0.2227 - accuracy: 0.6461\n",
      "382/382 [==============================] - 0s 434us/step - loss: 0.2223 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 3s 776us/step - loss: 0.2227 - accuracy: 0.6476\n",
      "382/382 [==============================] - 0s 443us/step - loss: 0.2184 - accuracy: 0.6600\n",
      "3432/3432 [==============================] - 3s 775us/step - loss: 0.2224 - accuracy: 0.6471\n",
      "382/382 [==============================] - 0s 447us/step - loss: 0.2231 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 3s 825us/step - loss: 0.2215 - accuracy: 0.6522\n",
      "382/382 [==============================] - 0s 457us/step - loss: 0.2224 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 3s 817us/step - loss: 0.2214 - accuracy: 0.6452\n",
      "382/382 [==============================] - 0s 419us/step - loss: 0.2235 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 3s 819us/step - loss: 0.2224 - accuracy: 0.6467\n",
      "382/382 [==============================] - 0s 411us/step - loss: 0.2191 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 3s 833us/step - loss: 0.2228 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 444us/step - loss: 0.2176 - accuracy: 0.6425\n",
      "3432/3432 [==============================] - 3s 841us/step - loss: 0.2226 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 411us/step - loss: 0.2211 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 3s 784us/step - loss: 0.2226 - accuracy: 0.6415\n",
      "382/382 [==============================] - 0s 466us/step - loss: 0.2166 - accuracy: 0.6661\n",
      "3432/3432 [==============================] - 3s 786us/step - loss: 0.2227 - accuracy: 0.6458\n",
      "382/382 [==============================] - 0s 447us/step - loss: 0.2184 - accuracy: 0.6705\n",
      "3432/3432 [==============================] - 3s 809us/step - loss: 0.2225 - accuracy: 0.6443\n",
      "382/382 [==============================] - 0s 373us/step - loss: 0.2210 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 3s 831us/step - loss: 0.2227 - accuracy: 0.6487\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2165 - accuracy: 0.6547\n",
      "   1/3432 [..............................] - ETA: 0s - loss: 0.2501 - accuracy: 0.3333WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0156s). Check your callbacks.\n",
      "3432/3432 [==============================] - 3s 829us/step - loss: 0.2224 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 426us/step - loss: 0.2231 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 3s 842us/step - loss: 0.2225 - accuracy: 0.6473\n",
      "382/382 [==============================] - 0s 434us/step - loss: 0.2232 - accuracy: 0.6329\n",
      "3432/3432 [==============================] - 3s 939us/step - loss: 0.2226 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 506us/step - loss: 0.2209 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 4s 1ms/step - loss: 0.2224 - accuracy: 0.6481\n",
      "382/382 [==============================] - 0s 473us/step - loss: 0.2216 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 3s 866us/step - loss: 0.2227 - accuracy: 0.6457\n",
      "382/382 [==============================] - 0s 420us/step - loss: 0.2159 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 3s 797us/step - loss: 0.2223 - accuracy: 0.6454\n",
      "382/382 [==============================] - 0s 460us/step - loss: 0.2229 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 3s 843us/step - loss: 0.2235 - accuracy: 0.6417\n",
      "382/382 [==============================] - 0s 408us/step - loss: 0.2155 - accuracy: 0.6661\n",
      "3432/3432 [==============================] - 3s 843us/step - loss: 0.2236 - accuracy: 0.6421\n",
      "382/382 [==============================] - 0s 466us/step - loss: 0.2190 - accuracy: 0.6600\n",
      "3432/3432 [==============================] - 3s 838us/step - loss: 0.2218 - accuracy: 0.6462\n",
      "382/382 [==============================] - 0s 487us/step - loss: 0.2211 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 3s 860us/step - loss: 0.2228 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 545us/step - loss: 0.2142 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 3s 913us/step - loss: 0.2221 - accuracy: 0.6461\n",
      "382/382 [==============================] - 0s 447us/step - loss: 0.2238 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 3s 904us/step - loss: 0.2223 - accuracy: 0.6467\n",
      "382/382 [==============================] - 0s 446us/step - loss: 0.2230 - accuracy: 0.6329\n",
      "3432/3432 [==============================] - 3s 799us/step - loss: 0.2227 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 393us/step - loss: 0.2213 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 3s 860us/step - loss: 0.2226 - accuracy: 0.6452\n",
      "382/382 [==============================] - 0s 473us/step - loss: 0.2242 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 3s 852us/step - loss: 0.2231 - accuracy: 0.6464\n",
      "382/382 [==============================] - 0s 450us/step - loss: 0.2155 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 3s 851us/step - loss: 0.2224 - accuracy: 0.6474\n",
      "382/382 [==============================] - 0s 459us/step - loss: 0.2209 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 3s 873us/step - loss: 0.2230 - accuracy: 0.6392\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 0s 477us/step - loss: 0.2175 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 3s 866us/step - loss: 0.2230 - accuracy: 0.6409\n",
      "382/382 [==============================] - 0s 485us/step - loss: 0.2183 - accuracy: 0.6652\n",
      "3432/3432 [==============================] - 3s 825us/step - loss: 0.2222 - accuracy: 0.6449\n",
      "382/382 [==============================] - 0s 480us/step - loss: 0.2239 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 3s 847us/step - loss: 0.2236 - accuracy: 0.6420\n",
      "382/382 [==============================] - 0s 458us/step - loss: 0.2163 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 3s 876us/step - loss: 0.2223 - accuracy: 0.6477\n",
      "382/382 [==============================] - 0s 522us/step - loss: 0.2224 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 3s 862us/step - loss: 0.2225 - accuracy: 0.6465\n",
      "382/382 [==============================] - 0s 457us/step - loss: 0.2272 - accuracy: 0.6267\n",
      "3432/3432 [==============================] - 3s 851us/step - loss: 0.2223 - accuracy: 0.6452\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.2664 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0156s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 464us/step - loss: 0.2226 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 3s 849us/step - loss: 0.2222 - accuracy: 0.6471\n",
      "382/382 [==============================] - 0s 476us/step - loss: 0.2206 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 3s 877us/step - loss: 0.2229 - accuracy: 0.6474\n",
      "382/382 [==============================] - 0s 432us/step - loss: 0.2199 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 3s 797us/step - loss: 0.2222 - accuracy: 0.6443\n",
      "382/382 [==============================] - 0s 405us/step - loss: 0.2199 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 3s 796us/step - loss: 0.2231 - accuracy: 0.6448\n",
      "382/382 [==============================] - 0s 429us/step - loss: 0.2150 - accuracy: 0.6696\n",
      "3432/3432 [==============================] - 3s 801us/step - loss: 0.2229 - accuracy: 0.6457\n",
      "382/382 [==============================] - 0s 429us/step - loss: 0.2155 - accuracy: 0.6626\n",
      "3432/3432 [==============================] - 3s 848us/step - loss: 0.2220 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 454us/step - loss: 0.2206 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 3s 852us/step - loss: 0.2228 - accuracy: 0.6488\n",
      "382/382 [==============================] - 0s 486us/step - loss: 0.2173 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 3s 849us/step - loss: 0.2226 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 435us/step - loss: 0.2268 - accuracy: 0.6407\n",
      "3432/3432 [==============================] - 3s 877us/step - loss: 0.2223 - accuracy: 0.6485\n",
      "382/382 [==============================] - 0s 461us/step - loss: 0.2235 - accuracy: 0.6390\n",
      "3432/3432 [==============================] - 3s 894us/step - loss: 0.2220 - accuracy: 0.6463\n",
      "382/382 [==============================] - 0s 458us/step - loss: 0.2247 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 3s 815us/step - loss: 0.2221 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 406us/step - loss: 0.2225 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 3s 797us/step - loss: 0.2227 - accuracy: 0.6432\n",
      "382/382 [==============================] - 0s 443us/step - loss: 0.2164 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 3s 867us/step - loss: 0.2227 - accuracy: 0.6420\n",
      "382/382 [==============================] - 0s 463us/step - loss: 0.2223 - accuracy: 0.6302\n",
      "3432/3432 [==============================] - 3s 852us/step - loss: 0.2229 - accuracy: 0.6437\n",
      "382/382 [==============================] - 0s 405us/step - loss: 0.2145 - accuracy: 0.6696\n",
      "3432/3432 [==============================] - 3s 856us/step - loss: 0.2228 - accuracy: 0.6443\n",
      "382/382 [==============================] - 0s 409us/step - loss: 0.2156 - accuracy: 0.6617\n",
      "3432/3432 [==============================] - 3s 850us/step - loss: 0.2225 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 439us/step - loss: 0.2210 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 3s 863us/step - loss: 0.2230 - accuracy: 0.6462\n",
      "382/382 [==============================] - 0s 384us/step - loss: 0.2168 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 3s 880us/step - loss: 0.2226 - accuracy: 0.6445\n",
      "382/382 [==============================] - 0s 483us/step - loss: 0.2223 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 3s 782us/step - loss: 0.2216 - accuracy: 0.6448\n",
      "382/382 [==============================] - 0s 418us/step - loss: 0.2288 - accuracy: 0.6407\n",
      "3432/3432 [==============================] - 3s 798us/step - loss: 0.2222 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 423us/step - loss: 0.2220 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 3s 870us/step - loss: 0.2228 - accuracy: 0.6429\n",
      "382/382 [==============================] - 0s 472us/step - loss: 0.2258 - accuracy: 0.6425\n",
      "3432/3432 [==============================] - 3s 844us/step - loss: 0.2230 - accuracy: 0.6465\n",
      "382/382 [==============================] - 0s 444us/step - loss: 0.2170 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 3s 841us/step - loss: 0.2224 - accuracy: 0.6463\n",
      "382/382 [==============================] - 0s 449us/step - loss: 0.2259 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 3s 846us/step - loss: 0.2226 - accuracy: 0.6449\n",
      "382/382 [==============================] - 0s 438us/step - loss: 0.2148 - accuracy: 0.6608\n",
      "3432/3432 [==============================] - 3s 883us/step - loss: 0.2230 - accuracy: 0.6425\n",
      "382/382 [==============================] - 0s 444us/step - loss: 0.2166 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 3s 803us/step - loss: 0.2225 - accuracy: 0.6423\n",
      "382/382 [==============================] - 0s 423us/step - loss: 0.2222 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 3s 787us/step - loss: 0.2235 - accuracy: 0.6453\n",
      "382/382 [==============================] - 0s 396us/step - loss: 0.2162 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 3s 831us/step - loss: 0.2226 - accuracy: 0.6439\n",
      "382/382 [==============================] - 0s 403us/step - loss: 0.2250 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 3s 843us/step - loss: 0.2222 - accuracy: 0.6438\n",
      "382/382 [==============================] - 0s 378us/step - loss: 0.2240 - accuracy: 0.6329\n",
      "3432/3432 [==============================] - 3s 841us/step - loss: 0.2226 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 439us/step - loss: 0.2249 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 3s 863us/step - loss: 0.2222 - accuracy: 0.6452\n",
      "382/382 [==============================] - 0s 406us/step - loss: 0.2210 - accuracy: 0.6416\n",
      "3432/3432 [==============================] - 3s 893us/step - loss: 0.2232 - accuracy: 0.6424\n",
      "382/382 [==============================] - 0s 438us/step - loss: 0.2158 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 3s 812us/step - loss: 0.2226 - accuracy: 0.6473\n",
      "382/382 [==============================] - 0s 448us/step - loss: 0.2210 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 3s 816us/step - loss: 0.2233 - accuracy: 0.6451\n",
      "382/382 [==============================] - 0s 438us/step - loss: 0.2153 - accuracy: 0.6661\n",
      "3432/3432 [==============================] - 3s 831us/step - loss: 0.2225 - accuracy: 0.6445\n",
      "382/382 [==============================] - 0s 456us/step - loss: 0.2189 - accuracy: 0.6600\n",
      "3432/3432 [==============================] - 3s 855us/step - loss: 0.2227 - accuracy: 0.6445\n",
      "382/382 [==============================] - 0s 455us/step - loss: 0.2222 - accuracy: 0.6399\n",
      "3432/3432 [==============================] - 3s 851us/step - loss: 0.2224 - accuracy: 0.6480\n",
      "382/382 [==============================] - 0s 393us/step - loss: 0.2260 - accuracy: 0.6521\n",
      "3814/3814 [==============================] - 3s 866us/step - loss: 0.2222 - accuracy: 0.6467\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "def model_nn(units='8', units2='8', drop='0,1', bias = 0.01, bias2 = 0.01, bias3 = 0.01):\n",
    "    model = Sequential()\n",
    "    #model.add(tf.keras.layers.Flatten())\n",
    "    model.add(Dense(264, input_dim=264, kernel_initializer='normal', activation='relu',bias_regularizer=l2(bias)))\n",
    "    model.add(Dense(units=units, kernel_initializer='normal', activation='relu',bias_regularizer=l2(bias2)))\n",
    "    model.add(Dense(units=units2, kernel_initializer='normal', activation='relu',bias_regularizer=l2(bias3)))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='MeanSquaredError', metrics=['accuracy'])\n",
    "    #model.fit(X_train, y_train, batch_size= 5, epochs=10, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=model_nn)\n",
    "params={'bias':[0.01, 0.02, 0.03, 0.04],\n",
    "        'bias2':[0.01, 0.02, 0.03, 0.04],\n",
    "        'bias3':[0.01, 0.02, 0.03, 0.04],\n",
    "        'units':[64],\n",
    "        'units2':[32],\n",
    "        'batch_size':[3], \n",
    "        'nb_epoch':[5]\n",
    "\n",
    "        }\n",
    "gs=GridSearchCV(estimator=model, param_grid=params, cv=10)\n",
    "# now fit the dataset to the GridSearchCV object. \n",
    "gs = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "799b2857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 3, 'bias': 0.01, 'nb_epoch': 5, 'units': 64, 'units2': 32}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params=gs.best_params_\n",
    "accuracy=gs.best_score_\n",
    "accuracy\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "969441d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ead0038",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
