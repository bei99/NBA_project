{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56f54684",
   "metadata": {},
   "source": [
    "#### Import the relevant librries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "121a30ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.callbacks import TensorBoard\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import pickle\n",
    "import time, datetime, os\n",
    "%reload_ext tensorboard"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bfba15b",
   "metadata": {},
   "source": [
    "####  Set tensorboard and import final_dataset as stats.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "06759a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "NAME = \"264x32x16x1_MSE_sv{}\".format(int(time.time()))\n",
    "log_dir = \"logs/fit/\" + NAME\n",
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "stats = pd.read_csv(r'Data\\final_dataset.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "968da41f",
   "metadata": {},
   "source": [
    "#### Slice stats into X and y. Split the data into training and test set (80/20) and normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5545731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = stats.iloc[:,3:-4]\n",
    "y = stats.iloc[:,-1:]\n",
    "random_state = 12\n",
    "#split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, shuffle = True, random_state=random_state)\n",
    "X_train = tf.keras.utils.normalize(X_train, axis=1)\n",
    "X_test = tf.keras.utils.normalize(X_test, axis=1)\n",
    "stats['Results'] = stats['Results'].astype('float32')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23759326",
   "metadata": {},
   "source": [
    "### Define the custom loss functions\n",
    "\n",
    "##### BCE: Binary-cross entropy with added parameters to optimize our return on investment.\n",
    "\n",
    "$L(y\\hat, y) = -\\sum\\limits_{i=1}^{m} (Odds_{1i}*y_{i}-1) * log(Odds_{1i}*\\hat y_{i}-1) + (Odds_{2i}(1 - y_{i})-1) * log(Odds_{2i}*(1- \\hat y_{i}) -1)$\n",
    "\n",
    "Source: https://www.vantage-ai.com/en/blog/beating-the-bookies-with-machine-learning\n",
    "\n",
    "We will try to fit these loss function in a near future.\n",
    "\n",
    "##### MSE: Mean Squared Error with odds decorrelation\n",
    "\n",
    "$L(p\\hat, y)= \\frac{1}{N} \\sum\\limits_{i=1}^{N}(\\hat p_{i} - y_{i})^{2} - C * (\\hat p_{i} - \\frac {1}{Odds_{i}})^{2}$\n",
    "\n",
    "The first part $(\\hat p_{i} - y_{i})^{2}$ is the Mean Squared Error, the difference between the predicted outcome versus the actual aoutcome. For the second part, C is a constant that determines the significance of the decorrelation effect. $(\\hat p_{i} - \\frac {1}{Odds_{i}})^{2}$, $\\hat p_{i}$ is the predicted probability for the home team and $\\frac {1}{Odds_{i}}$ is the probability that the bookmakers gives to the home team victory.\n",
    "\n",
    "Source: Hubáček, Ondřej, Gustav Šourek, and Filip Železný. \"Exploiting sports-betting market using machine learning.\" International Journal of Forecasting 35.2 (2019): 783-796.\n",
    "\n",
    "Keras only allow the parameters y_pred and y_true in the loss functions, to make our custom loss function we pass a wrapper function with our extra parameter, the odds.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "77f61eae",
   "metadata": {},
   "outputs": [],
   "source": [
    "odds1 = stats.iloc[:, -3:-2].values\n",
    "odds1_prob = 1/odds1\n",
    "\n",
    "def coef_bce(y_pred,y_true, odds1, odds2):\n",
    "    return -1 * K.mean((odds1 * y_true -1) * K.log(odds1 * y_pred -1) + (odds2 * (1- y_true) -1) * K.log(odds2 * (1-y_pred)-1))\n",
    "\n",
    "def bce_custom(odds1, odds2):\n",
    "    def bce(y_pred, y_true):\n",
    "        return coef_bce(y_pred, y_true, odds1, odds2)\n",
    "    return bce\n",
    "\n",
    "#loss_bce = bce_custom(odds1, odds2)\n",
    "\n",
    "\n",
    "def coef_mse(y_pred, y_true, odds_game ):\n",
    "    mse = K.square(y_pred - y_true)  #squared difference\n",
    "    odds = 0.05 * K.square(y_pred - odds_game)   \n",
    "    loss = K.mean(mse - odds , axis=-1) #mean over last dimension\n",
    "    return loss\n",
    "\n",
    "def mse_custom(odds_game):\n",
    "    def mse( y_pred, y_true):\n",
    "        return coef_mse(y_pred, y_true, odds_game)\n",
    "    return mse\n",
    "\n",
    "loss_mse = mse_custom(odds1_prob)\n",
    "\n",
    "\n",
    "def mse_simple(y_true, y_pred):\n",
    "    mse = math_ops.squared_difference(y_pred, y_true) \n",
    "    loss = K.mean(mse, axis=-1)\n",
    "    return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fb5df3",
   "metadata": {},
   "source": [
    "### Model Architecture:\n",
    "After configuring GridSearch, the best parameters where:\n",
    "- layers: 64x32 // Input is 264(n. of features) and output is 1. So (264 x 64 x 32 x 1)\n",
    "- epochs: 5\n",
    "- batch size: 3\n",
    "- regularisation: l2(0.01)\n",
    "- activation function: ReLU except output layer (sigmoid)\n",
    "- optimizer: Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9161915b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "    2/11440 [..............................] - ETA: 32:27 - loss: 0.2398 - accuracy: 0.5000 WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.3406s). Check your callbacks.\n",
      "11440/11440 [==============================] - 7s 639us/step - loss: 0.2089 - accuracy: 0.6448 - val_loss: 0.1975 - val_accuracy: 0.6591\n",
      "Epoch 2/5\n",
      "11440/11440 [==============================] - 7s 635us/step - loss: 0.2040 - accuracy: 0.6548 - val_loss: 0.2016 - val_accuracy: 0.6580\n",
      "Epoch 3/5\n",
      "11440/11440 [==============================] - 7s 635us/step - loss: 0.2013 - accuracy: 0.6618 - val_loss: 0.1964 - val_accuracy: 0.6685\n",
      "Epoch 4/5\n",
      "11440/11440 [==============================] - 7s 619us/step - loss: 0.1998 - accuracy: 0.6655 - val_loss: 0.1955 - val_accuracy: 0.6752\n",
      "Epoch 5/5\n",
      "11440/11440 [==============================] - 7s 607us/step - loss: 0.1977 - accuracy: 0.6702 - val_loss: 0.1988 - val_accuracy: 0.6647\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1ffe93243a0>"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#opt = tf.keras.optimizers.Adam(clipnorm=0.3)\n",
    "#bias_regularizer=l2(0.01)\n",
    "\n",
    "model = Sequential()\n",
    "#model.add(tf.keras.layers.Flatten())\n",
    "model.add(Dense(264, input_dim=264, kernel_initializer='normal', activation='relu',bias_regularizer=l2(0.01)))\n",
    "model.add(Dense(64, kernel_initializer='normal', activation='relu',bias_regularizer=l2(0.01)))\n",
    "model.add(Dense(32, kernel_initializer='normal', activation='relu',bias_regularizer=l2(0.01)))\n",
    "model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "model.compile(optimizer='Adam', loss=loss_mse, metrics=['accuracy'])\n",
    "model.fit(X_train, y_train, batch_size= 1, epochs=5, validation_data=(X_test, y_test),callbacks=[tensorboard_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "ae6eafc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_loss, val_acc = model.evaluate(X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d13818c8",
   "metadata": {},
   "source": [
    "### Retrieve the information attached to the predictions and  store the predictions\n",
    "\n",
    "We attach the prediction with the outcome. We also retrieve the infomration regarding the game such as the data, the teams, the score and the odds so we can later perform an Error analysis. We finally store the dataframe in a csv file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f1875eec",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prediction = model.predict(X_test[:])\n",
    "label = y_test[:]\n",
    "prediction_l = prediction.tolist()\n",
    "pred =pd.DataFrame(prediction_l, columns=['prediction'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "d799fcf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>Results</th>\n",
       "      <th>GAME_DATE</th>\n",
       "      <th>HOME</th>\n",
       "      <th>AWAY</th>\n",
       "      <th>Odds1</th>\n",
       "      <th>Odds2</th>\n",
       "      <th>Score</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8985</td>\n",
       "      <td>1</td>\n",
       "      <td>04/03/2017</td>\n",
       "      <td>SAS</td>\n",
       "      <td>MIN</td>\n",
       "      <td>1.30</td>\n",
       "      <td>3.75</td>\n",
       "      <td>97:90</td>\n",
       "      <td>0.808359</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7320</td>\n",
       "      <td>1</td>\n",
       "      <td>03/12/2015</td>\n",
       "      <td>TOR</td>\n",
       "      <td>DEN</td>\n",
       "      <td>1.18</td>\n",
       "      <td>5.33</td>\n",
       "      <td>105:106</td>\n",
       "      <td>0.432308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1662</td>\n",
       "      <td>0</td>\n",
       "      <td>10/02/2010</td>\n",
       "      <td>CHI</td>\n",
       "      <td>ORL</td>\n",
       "      <td>2.67</td>\n",
       "      <td>1.50</td>\n",
       "      <td>87:107</td>\n",
       "      <td>0.863924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2694</td>\n",
       "      <td>0</td>\n",
       "      <td>04/02/2011</td>\n",
       "      <td>TOR</td>\n",
       "      <td>MIN</td>\n",
       "      <td>1.60</td>\n",
       "      <td>2.40</td>\n",
       "      <td>111:100</td>\n",
       "      <td>0.547415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3665</td>\n",
       "      <td>1</td>\n",
       "      <td>16/03/2012</td>\n",
       "      <td>ORL</td>\n",
       "      <td>BKN</td>\n",
       "      <td>1.10</td>\n",
       "      <td>7.57</td>\n",
       "      <td>86:70</td>\n",
       "      <td>0.643577</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2846</th>\n",
       "      <td>3446</td>\n",
       "      <td>0</td>\n",
       "      <td>15/02/2012</td>\n",
       "      <td>CLE</td>\n",
       "      <td>IND</td>\n",
       "      <td>2.03</td>\n",
       "      <td>1.80</td>\n",
       "      <td>98:87</td>\n",
       "      <td>0.384152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2847</th>\n",
       "      <td>10005</td>\n",
       "      <td>1</td>\n",
       "      <td>23/02/2018</td>\n",
       "      <td>IND</td>\n",
       "      <td>ATL</td>\n",
       "      <td>1.31</td>\n",
       "      <td>3.67</td>\n",
       "      <td>116:93</td>\n",
       "      <td>0.491052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2848</th>\n",
       "      <td>4325</td>\n",
       "      <td>0</td>\n",
       "      <td>05/01/2013</td>\n",
       "      <td>BKN</td>\n",
       "      <td>SAC</td>\n",
       "      <td>1.33</td>\n",
       "      <td>3.52</td>\n",
       "      <td>113:93</td>\n",
       "      <td>0.683397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2849</th>\n",
       "      <td>5980</td>\n",
       "      <td>1</td>\n",
       "      <td>27/03/2014</td>\n",
       "      <td>MIL</td>\n",
       "      <td>LAL</td>\n",
       "      <td>1.72</td>\n",
       "      <td>2.19</td>\n",
       "      <td>108:105</td>\n",
       "      <td>0.674776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2850</th>\n",
       "      <td>14205</td>\n",
       "      <td>1</td>\n",
       "      <td>30/03/2022</td>\n",
       "      <td>CLE</td>\n",
       "      <td>DAL</td>\n",
       "      <td>2.09</td>\n",
       "      <td>1.79</td>\n",
       "      <td>112:120</td>\n",
       "      <td>0.319118</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2851 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  Results   GAME_DATE HOME AWAY  Odds1  Odds2    Score  prediction\n",
       "0      8985        1  04/03/2017  SAS  MIN   1.30   3.75   97:90     0.808359\n",
       "1      7320        1  03/12/2015  TOR  DEN   1.18   5.33  105:106    0.432308\n",
       "2      1662        0  10/02/2010  CHI  ORL   2.67   1.50   87:107    0.863924\n",
       "3      2694        0  04/02/2011  TOR  MIN   1.60   2.40  111:100    0.547415\n",
       "4      3665        1  16/03/2012  ORL  BKN   1.10   7.57    86:70    0.643577\n",
       "...     ...      ...         ...  ...  ...    ...    ...      ...         ...\n",
       "2846   3446        0  15/02/2012  CLE  IND   2.03   1.80    98:87    0.384152\n",
       "2847  10005        1  23/02/2018  IND  ATL   1.31   3.67   116:93    0.491052\n",
       "2848   4325        0  05/01/2013  BKN  SAC   1.33   3.52   113:93    0.683397\n",
       "2849   5980        1  27/03/2014  MIL  LAL   1.72   2.19  108:105    0.674776\n",
       "2850  14205        1  30/03/2022  CLE  DAL   2.09   1.79  112:120    0.319118\n",
       "\n",
       "[2851 rows x 9 columns]"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats.reset_index\n",
    "index = stats[['GAME_DATE', 'HOME', 'AWAY','Odds1', 'Odds2', 'Score']]\n",
    "data = label.join(index)\n",
    "data.reset_index(inplace=True)\n",
    "pred_data = data.join(pred)\n",
    "pred_data.to_csv('predicted_data.csv')\n",
    "pred_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afb35d1f",
   "metadata": {},
   "source": [
    "### GridSearchCV\n",
    "\n",
    "We use the GridSearchCV from sklearn to find the parameters that best optimize our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d59f82ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3432/3432 [==============================] - 2s 589us/step - loss: 0.2223 - accuracy: 0.6420\n",
      "382/382 [==============================] - 0s 381us/step - loss: 0.2202 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 592us/step - loss: 0.2216 - accuracy: 0.6480\n",
      "382/382 [==============================] - 0s 362us/step - loss: 0.2235 - accuracy: 0.6320\n",
      "3432/3432 [==============================] - 2s 580us/step - loss: 0.2220 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 376us/step - loss: 0.2227 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 577us/step - loss: 0.2219 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 373us/step - loss: 0.2205 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 586us/step - loss: 0.2226 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 358us/step - loss: 0.2165 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 586us/step - loss: 0.2222 - accuracy: 0.6460\n",
      "382/382 [==============================] - 0s 355us/step - loss: 0.2235 - accuracy: 0.6425\n",
      "3432/3432 [==============================] - 2s 590us/step - loss: 0.2225 - accuracy: 0.6453\n",
      "382/382 [==============================] - 0s 351us/step - loss: 0.2160 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 580us/step - loss: 0.2226 - accuracy: 0.6466\n",
      "382/382 [==============================] - 0s 383us/step - loss: 0.2211 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 581us/step - loss: 0.2221 - accuracy: 0.6445\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2193 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 2s 579us/step - loss: 0.2224 - accuracy: 0.6417\n",
      "382/382 [==============================] - 0s 389us/step - loss: 0.2138 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 2s 586us/step - loss: 0.2224 - accuracy: 0.6442\n",
      "382/382 [==============================] - 0s 398us/step - loss: 0.2222 - accuracy: 0.6556\n",
      "3432/3432 [==============================] - 2s 586us/step - loss: 0.2219 - accuracy: 0.6444\n",
      "382/382 [==============================] - 0s 376us/step - loss: 0.2224 - accuracy: 0.6442\n",
      "3432/3432 [==============================] - 2s 587us/step - loss: 0.2218 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 364us/step - loss: 0.2215 - accuracy: 0.6381\n",
      "3432/3432 [==============================] - 2s 589us/step - loss: 0.2222 - accuracy: 0.6485\n",
      "382/382 [==============================] - 0s 387us/step - loss: 0.2214 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 2s 589us/step - loss: 0.2229 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 357us/step - loss: 0.2175 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 585us/step - loss: 0.2219 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 374us/step - loss: 0.2210 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 2s 585us/step - loss: 0.2228 - accuracy: 0.6439\n",
      "382/382 [==============================] - 0s 378us/step - loss: 0.2153 - accuracy: 0.6626\n",
      "3432/3432 [==============================] - 2s 582us/step - loss: 0.2226 - accuracy: 0.6467\n",
      "382/382 [==============================] - 0s 412us/step - loss: 0.2168 - accuracy: 0.6661\n",
      "3432/3432 [==============================] - 2s 592us/step - loss: 0.2225 - accuracy: 0.6448\n",
      "382/382 [==============================] - 0s 382us/step - loss: 0.2186 - accuracy: 0.6600\n",
      "3432/3432 [==============================] - 2s 581us/step - loss: 0.2229 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 380us/step - loss: 0.2174 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 2s 593us/step - loss: 0.2222 - accuracy: 0.6465\n",
      "382/382 [==============================] - 0s 360us/step - loss: 0.2235 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 588us/step - loss: 0.2219 - accuracy: 0.6478\n",
      "382/382 [==============================] - 0s 381us/step - loss: 0.2236 - accuracy: 0.6364\n",
      "   1/3432 [..............................] - ETA: 0s - loss: 0.2501 - accuracy: 0.3333WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0156s). Check your callbacks.\n",
      "3432/3432 [==============================] - 2s 593us/step - loss: 0.2221 - accuracy: 0.6462\n",
      "382/382 [==============================] - 0s 393us/step - loss: 0.2219 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 589us/step - loss: 0.2224 - accuracy: 0.6428\n",
      "  1/382 [..............................] - ETA: 0s - loss: 0.2895 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_test_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_test_batch_end` time: 0.0156s). Check your callbacks.\n",
      "382/382 [==============================] - 0s 403us/step - loss: 0.2211 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 594us/step - loss: 0.2230 - accuracy: 0.6405\n",
      "382/382 [==============================] - 0s 343us/step - loss: 0.2174 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 2s 587us/step - loss: 0.2225 - accuracy: 0.6430\n",
      "382/382 [==============================] - 0s 363us/step - loss: 0.2207 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 589us/step - loss: 0.2229 - accuracy: 0.6426\n",
      "382/382 [==============================] - 0s 357us/step - loss: 0.2191 - accuracy: 0.6643\n",
      "3432/3432 [==============================] - 2s 589us/step - loss: 0.2226 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 380us/step - loss: 0.2176 - accuracy: 0.6503\n",
      "3432/3432 [==============================] - 2s 580us/step - loss: 0.2228 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 347us/step - loss: 0.2189 - accuracy: 0.6565\n",
      "3432/3432 [==============================] - 2s 580us/step - loss: 0.2230 - accuracy: 0.6410\n",
      "382/382 [==============================] - 0s 349us/step - loss: 0.2197 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 592us/step - loss: 0.2217 - accuracy: 0.6447\n",
      "382/382 [==============================] - 0s 372us/step - loss: 0.2232 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 597us/step - loss: 0.2221 - accuracy: 0.6460\n",
      "382/382 [==============================] - 0s 352us/step - loss: 0.2247 - accuracy: 0.6233\n",
      "3432/3432 [==============================] - 2s 602us/step - loss: 0.2219 - accuracy: 0.6484\n",
      "382/382 [==============================] - 0s 349us/step - loss: 0.2230 - accuracy: 0.6503\n",
      "   1/3432 [..............................] - ETA: 0s - loss: 0.2500 - accuracy: 0.3333WARNING:tensorflow:Callbacks method `on_train_batch_begin` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_begin` time: 0.0156s). Check your callbacks.\n",
      "3432/3432 [==============================] - 2s 596us/step - loss: 0.2225 - accuracy: 0.6478\n",
      "382/382 [==============================] - 0s 360us/step - loss: 0.2193 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 607us/step - loss: 0.2226 - accuracy: 0.6439\n",
      "382/382 [==============================] - 0s 402us/step - loss: 0.2233 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 604us/step - loss: 0.2223 - accuracy: 0.6423\n",
      "382/382 [==============================] - 0s 383us/step - loss: 0.2256 - accuracy: 0.6477\n",
      "   1/3432 [..............................] - ETA: 0s - loss: 0.2499 - accuracy: 0.6667WARNING:tensorflow:Callbacks method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0000s vs `on_train_batch_end` time: 0.0156s). Check your callbacks.\n",
      "3432/3432 [==============================] - 2s 610us/step - loss: 0.2227 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 381us/step - loss: 0.2141 - accuracy: 0.6661\n",
      "3432/3432 [==============================] - 2s 619us/step - loss: 0.2226 - accuracy: 0.6464\n",
      "382/382 [==============================] - 0s 376us/step - loss: 0.2154 - accuracy: 0.6617\n",
      "3432/3432 [==============================] - 2s 631us/step - loss: 0.2229 - accuracy: 0.6463\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 0s 394us/step - loss: 0.2195 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 2s 608us/step - loss: 0.2225 - accuracy: 0.6455\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2143 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 2s 620us/step - loss: 0.2222 - accuracy: 0.6464\n",
      "382/382 [==============================] - 0s 386us/step - loss: 0.2226 - accuracy: 0.6538\n",
      "3432/3432 [==============================] - 2s 622us/step - loss: 0.2220 - accuracy: 0.6458\n",
      "382/382 [==============================] - 0s 370us/step - loss: 0.2255 - accuracy: 0.6329\n",
      "3432/3432 [==============================] - 2s 617us/step - loss: 0.2217 - accuracy: 0.6459\n",
      "382/382 [==============================] - 0s 389us/step - loss: 0.2298 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 619us/step - loss: 0.2226 - accuracy: 0.6496\n",
      "382/382 [==============================] - 0s 369us/step - loss: 0.2213 - accuracy: 0.6346\n",
      "3432/3432 [==============================] - 2s 610us/step - loss: 0.2227 - accuracy: 0.6414\n",
      "382/382 [==============================] - 0s 380us/step - loss: 0.2158 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 619us/step - loss: 0.2216 - accuracy: 0.6468\n",
      "382/382 [==============================] - 0s 395us/step - loss: 0.2219 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 615us/step - loss: 0.2228 - accuracy: 0.6463\n",
      "382/382 [==============================] - 0s 376us/step - loss: 0.2158 - accuracy: 0.6713\n",
      "3432/3432 [==============================] - 2s 643us/step - loss: 0.2225 - accuracy: 0.6461\n",
      "382/382 [==============================] - 0s 414us/step - loss: 0.2149 - accuracy: 0.6617\n",
      "3432/3432 [==============================] - 2s 616us/step - loss: 0.2221 - accuracy: 0.6452\n",
      "382/382 [==============================] - 0s 415us/step - loss: 0.2221 - accuracy: 0.6477\n",
      "3432/3432 [==============================] - 2s 616us/step - loss: 0.2224 - accuracy: 0.6486\n",
      "382/382 [==============================] - 0s 384us/step - loss: 0.2158 - accuracy: 0.6573\n",
      "3432/3432 [==============================] - 2s 636us/step - loss: 0.2218 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2245 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 2s 620us/step - loss: 0.2216 - accuracy: 0.6464\n",
      "382/382 [==============================] - 0s 384us/step - loss: 0.2241 - accuracy: 0.6364\n",
      "3432/3432 [==============================] - 2s 621us/step - loss: 0.2219 - accuracy: 0.64870s - loss: 0.224\n",
      "382/382 [==============================] - 0s 392us/step - loss: 0.2213 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 622us/step - loss: 0.2226 - accuracy: 0.6464\n",
      "382/382 [==============================] - 0s 413us/step - loss: 0.2254 - accuracy: 0.6434\n",
      "3432/3432 [==============================] - 2s 614us/step - loss: 0.2227 - accuracy: 0.6462\n",
      "382/382 [==============================] - 0s 378us/step - loss: 0.2141 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 614us/step - loss: 0.2224 - accuracy: 0.6448\n",
      "382/382 [==============================] - 0s 401us/step - loss: 0.2237 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 616us/step - loss: 0.2232 - accuracy: 0.6434\n",
      "382/382 [==============================] - 0s 391us/step - loss: 0.2151 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 628us/step - loss: 0.2229 - accuracy: 0.6446\n",
      "382/382 [==============================] - 0s 393us/step - loss: 0.2149 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 2s 618us/step - loss: 0.2227 - accuracy: 0.6456\n",
      "382/382 [==============================] - 0s 375us/step - loss: 0.2202 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 638us/step - loss: 0.2231 - accuracy: 0.6445\n",
      "382/382 [==============================] - 0s 385us/step - loss: 0.2150 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 2s 641us/step - loss: 0.2220 - accuracy: 0.6429\n",
      "382/382 [==============================] - 0s 405us/step - loss: 0.2235 - accuracy: 0.6512\n",
      "3432/3432 [==============================] - 2s 635us/step - loss: 0.2220 - accuracy: 0.6426\n",
      "382/382 [==============================] - 0s 396us/step - loss: 0.2240 - accuracy: 0.6381\n",
      "3432/3432 [==============================] - 2s 632us/step - loss: 0.2228 - accuracy: 0.6421\n",
      "382/382 [==============================] - 0s 384us/step - loss: 0.2210 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 629us/step - loss: 0.2219 - accuracy: 0.6464\n",
      "382/382 [==============================] - 0s 397us/step - loss: 0.2221 - accuracy: 0.6451\n",
      "3432/3432 [==============================] - 2s 632us/step - loss: 0.2231 - accuracy: 0.6417\n",
      "382/382 [==============================] - 0s 381us/step - loss: 0.2151 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 642us/step - loss: 0.2227 - accuracy: 0.6452\n",
      "382/382 [==============================] - 0s 401us/step - loss: 0.2216 - accuracy: 0.6346\n",
      "3432/3432 [==============================] - 2s 623us/step - loss: 0.2233 - accuracy: 0.6401\n",
      "382/382 [==============================] - 0s 379us/step - loss: 0.2148 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 617us/step - loss: 0.2229 - accuracy: 0.6436\n",
      "382/382 [==============================] - 0s 398us/step - loss: 0.2173 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 621us/step - loss: 0.2222 - accuracy: 0.6420\n",
      "382/382 [==============================] - 0s 395us/step - loss: 0.2184 - accuracy: 0.6635\n",
      "3432/3432 [==============================] - 2s 633us/step - loss: 0.2227 - accuracy: 0.6467\n",
      "382/382 [==============================] - 0s 397us/step - loss: 0.2201 - accuracy: 0.6591\n",
      "3432/3432 [==============================] - 2s 635us/step - loss: 0.2226 - accuracy: 0.6468\n",
      "382/382 [==============================] - 0s 367us/step - loss: 0.2219 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 2s 636us/step - loss: 0.2218 - accuracy: 0.6483\n",
      "382/382 [==============================] - 0s 360us/step - loss: 0.2244 - accuracy: 0.6399\n",
      "3432/3432 [==============================] - 2s 630us/step - loss: 0.2224 - accuracy: 0.6429\n",
      "382/382 [==============================] - 0s 370us/step - loss: 0.2222 - accuracy: 0.6486\n",
      "3432/3432 [==============================] - 2s 645us/step - loss: 0.2224 - accuracy: 0.6403\n",
      "382/382 [==============================] - 0s 366us/step - loss: 0.2221 - accuracy: 0.6469\n",
      "3432/3432 [==============================] - 2s 632us/step - loss: 0.2231 - accuracy: 0.6450\n",
      "382/382 [==============================] - 0s 348us/step - loss: 0.2194 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 624us/step - loss: 0.2228 - accuracy: 0.6407\n",
      "382/382 [==============================] - 0s 343us/step - loss: 0.2240 - accuracy: 0.6425\n",
      "3432/3432 [==============================] - 2s 626us/step - loss: 0.2224 - accuracy: 0.6455\n",
      "382/382 [==============================] - 0s 393us/step - loss: 0.2143 - accuracy: 0.6713\n",
      "3432/3432 [==============================] - 2s 632us/step - loss: 0.2230 - accuracy: 0.6415\n",
      "382/382 [==============================] - 0s 389us/step - loss: 0.2158 - accuracy: 0.6652\n",
      "3432/3432 [==============================] - 2s 632us/step - loss: 0.2224 - accuracy: 0.6442\n",
      "382/382 [==============================] - 0s 394us/step - loss: 0.2196 - accuracy: 0.6530\n",
      "3432/3432 [==============================] - 2s 653us/step - loss: 0.2228 - accuracy: 0.6440\n",
      "382/382 [==============================] - 0s 409us/step - loss: 0.2175 - accuracy: 0.6582\n",
      "3432/3432 [==============================] - 2s 641us/step - loss: 0.2224 - accuracy: 0.6445\n",
      "382/382 [==============================] - 0s 378us/step - loss: 0.2193 - accuracy: 0.6460\n",
      "3432/3432 [==============================] - 2s 653us/step - loss: 0.2219 - accuracy: 0.6459\n",
      "382/382 [==============================] - 0s 378us/step - loss: 0.2233 - accuracy: 0.6311\n",
      "3432/3432 [==============================] - 2s 650us/step - loss: 0.2225 - accuracy: 0.6452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "382/382 [==============================] - 0s 361us/step - loss: 0.2247 - accuracy: 0.6364\n",
      "3432/3432 [==============================] - 2s 644us/step - loss: 0.2220 - accuracy: 0.6442\n",
      "382/382 [==============================] - 0s 410us/step - loss: 0.2222 - accuracy: 0.6495\n",
      "3432/3432 [==============================] - 2s 640us/step - loss: 0.2236 - accuracy: 0.6421\n",
      "382/382 [==============================] - 0s 407us/step - loss: 0.2195 - accuracy: 0.6521\n",
      "3432/3432 [==============================] - 2s 642us/step - loss: 0.2228 - accuracy: 0.6470\n",
      "382/382 [==============================] - 0s 372us/step - loss: 0.2194 - accuracy: 0.6547\n",
      "3432/3432 [==============================] - 2s 636us/step - loss: 0.2234 - accuracy: 0.6437\n",
      "382/382 [==============================] - 0s 374us/step - loss: 0.2162 - accuracy: 0.6617\n",
      "3432/3432 [==============================] - 2s 637us/step - loss: 0.2231 - accuracy: 0.6452\n",
      "382/382 [==============================] - 0s 413us/step - loss: 0.2150 - accuracy: 0.6652\n",
      "3432/3432 [==============================] - 2s 636us/step - loss: 0.2230 - accuracy: 0.6451\n",
      "382/382 [==============================] - 0s 382us/step - loss: 0.2209 - accuracy: 0.6617\n",
      "3432/3432 [==============================] - 2s 630us/step - loss: 0.2235 - accuracy: 0.6427\n",
      "382/382 [==============================] - 0s 420us/step - loss: 0.2149 - accuracy: 0.6503\n",
      "3814/3814 [==============================] - 3s 661us/step - loss: 0.2219 - accuracy: 0.6451\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "def model_nn(units='8', units2='8', drop='0,1', bias = 0.01):\n",
    "    model = Sequential()\n",
    "    #model.add(tf.keras.layers.Flatten())\n",
    "    model.add(Dense(264, input_dim=264, kernel_initializer='normal', activation='relu',bias_regularizer=l2(bias)))\n",
    "    model.add(Dense(units=units, kernel_initializer='normal', activation='relu',bias_regularizer=l2(bias)))\n",
    "    model.add(Dense(units=units2, kernel_initializer='normal', activation='relu',bias_regularizer=l2(bias)))\n",
    "    model.add(Dense(1, kernel_initializer='normal', activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='adam', loss='MeanSquaredError', metrics=['accuracy'])\n",
    "    #model.fit(X_train, y_train, batch_size= 5, epochs=10, validation_data=(X_test, y_test), callbacks=[tensorboard_callback])\n",
    "    return model\n",
    "\n",
    "model = KerasClassifier(build_fn=model_nn)\n",
    "params={'bias':[0.01], \n",
    "        'units':[16,32, 64],\n",
    "        'units2':[16, 32, 64],\n",
    "        'batch_size':[3], \n",
    "        'nb_epoch':[5]\n",
    "\n",
    "        }\n",
    "gs=GridSearchCV(estimator=model, param_grid=params, cv=10)\n",
    "# now fit the dataset to the GridSearchCV object. \n",
    "gs = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "799b2857",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'batch_size': 3, 'bias': 0.01, 'nb_epoch': 5, 'units': 64, 'units2': 32}"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params=gs.best_params_\n",
    "accuracy=gs.best_score_\n",
    "accuracy\n",
    "best_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "969441d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%tensorboard --logdir logs/fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d60c178",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
